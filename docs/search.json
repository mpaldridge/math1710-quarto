[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MATH1710 Probability and Statistics 1",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "sections/L16-exponential-multi.html#exponential",
    "href": "sections/L16-exponential-multi.html#exponential",
    "title": "17  Exponential distribution and multiple continuous random variables",
    "section": "17.1 Exponential distribution",
    "text": "17.1 Exponential distribution\n\nAn important continuous distribution is the exponential distribution. The exponential distribution is often used to represent lengths of time: for example, the time between radioactive particles decaying, the time between eruptions of a volcano, or the time between buses arriving at a bus stop.\n\nA continuous random variable \\(X\\) is said to have the exponential distribution with rate \\(\\lambda > 0\\) if it has the PDF [ f(x) = ^{-x} , ] and 0 otherwise. We write \\(X \\sim \\text{Exp}(\\lambda)\\).\n\n\n\n\n\n\n\nThe length of time in years that a lightbulb works before needing to be replaced is modelled as an exponential distribution with rate \\(\\lambda = 2\\). What is the probability the lightbulb needs replacing within a year?\nIf \\(X \\sim \\text{Exp}(2)\\) is the lifetime of the lightbulb, we seek \\(\\mathbb P(X \\leq 1)\\). This is [ _{-}^1 f(x), x = _0^1 2 e^{-2x} , dx = _0^1 = -e^{-2} -(-1) = 1 - e^{-2} = 0.864. ]\n\n\nSuppose \\(X \\sim \\text{Exp}(\\lambda)\\). Then:\n\n\\(f\\) is indeed a PDF, in that \\(\\displaystyle\\int_0^\\infty f(x)\\,\\mathrm{d}x = 1\\);\nthe CDF of \\(X\\) is \\(F(x) = 1 - \\mathrm{e}^{-\\lambda x}\\);\nthe expectation of \\(X\\) is \\(\\mathbb EX = \\displaystyle\\frac{1}{\\lambda}\\);\nthe variance of \\(X\\) is \\(\\Var(X) = \\displaystyle\\frac{1}{\\lambda^2}\\).\n\n\n\nReturning to the lightbulb example, where \\(X \\sim \\text{Exp}(2)\\), we see that the average lifetime of a lightbulb is \\(\\mathbb EX = \\frac12\\) a year with variance \\(\\Var(X) = \\frac14\\).\nIf we wanted to calculate \\(\\mathbb P(1 \\leq X \\leq 3)\\), we could do this by integrating the PDF between 1 and 3. Alternatively, we could use the CDF: [ P(1 X ) = F(3) - F(1) = (1 - ^{-2}) - (1 - ^{-2}) = ^{-2} - ^{-6} = 0.132 . ]\n\n\nProof. of Theorem @ref(thm:exp-prop). For part 1, [ _0{-x},x = _0^= -0 -(-1) = 1 . ]\nSimilarly for part 2, [ F(x) = _0^x ^{-y},y = _0^x = -^{-x} -(-1) = 1 - ^{-x}. ]\nFor part 3, we use integration by parts with \\(u = x\\) and \\(v' = \\lambda \\mathrm{e}^{-\\lambda x}\\), so \\(u' = 1\\) and \\(v = -\\mathrm{e}^{-\\lambda x}\\). We get \\[\\begin{align*}\n\\mathbb EX &= \\int_0^\\infty x  \\lambda \\mathrm{e}^{-\\lambda x}\\,\\mathrm{d}x \\\\\n  &= \\big[-x \\mathrm{e}^{-\\lambda x}\\big]_0^\\infty + \\int_0^\\infty \\mathrm{e}^{-\\lambda x}\\,\\mathrm{d}x \\\\\n  &= -0 - (-0) + \\left[ -\\frac{1}{\\lambda} \\mathrm{e}^{-\\lambda x} \\right]_0^\\infty \\\\\n  &= -0 - \\left(- \\frac{1}{\\lambda}\\right) \\\\\n  &= \\frac{1}{\\lambda}\n\\end{align*}\\]\nFor part 4, we use integration by parts with \\(u = x^2\\) and \\(v' = \\lambda \\mathrm{e}^{-\\lambda x}\\), so \\(u' = 2x\\) and \\(v = -\\mathrm{e}^{-\\lambda x}\\) again. We get \\[\\begin{align*}\n\\mathbb EX^2 &= \\int_0^\\infty x^2  \\lambda \\mathrm{e}^{-\\lambda x}\\,\\mathrm{d}x \\\\\n  &= \\big[-x^2 \\mathrm{e}^{-\\lambda x}\\big]_0^\\infty + \\int_0^\\infty 2x \\mathrm{e}^{-\\lambda x}\\,\\mathrm{d}x \\\\\n  &= -0 - (-0) + \\frac{2}{\\lambda} \\int_0^\\infty x  \\lambda x \\mathrm{e}^{-\\lambda x}\\,\\mathrm{d}x \\\\\n  &= \\frac{2}{\\lambda} \\mathbb EX \\\\\n  &= \\frac{2}{\\lambda^2} ,\n\\end{align*}\\] where we used a cunning trick on the integral on the right – spotting that we could turn it into the expectation, which is \\(1/\\lambda\\), by part 3 – to save us the effort of calculating it again. Hence [ (X) = EX^2 - ()^2 = - = . ]"
  },
  {
    "objectID": "sections/L16-exponential-multi.html#continuous-multiple",
    "href": "sections/L16-exponential-multi.html#continuous-multiple",
    "title": "17  Exponential distribution and multiple continuous random variables",
    "section": "17.2 Multiple continuous random variables",
    "text": "17.2 Multiple continuous random variables\nThe theory we set up for two or more discrete random variables also works for two or more continuous random variables.\nNow, the intensity of probability for \\((X,Y)\\) being around \\((x,y)\\) is given by the joint probability density function \\(f_{X,Y}\\). In particular for \\(a \\leq b\\) and \\(c \\leq d\\), we have [ P(a X b c Y d ) = {x = a}^b {y = c}^d f_{X,Y}(x,y), dx ,dy .]\n\n\n\n\n\n\n\nDiscrete random variables\nContinuous random variables\n\n\n\n\nWe can get the marginal PMF \\(p_X\\) of \\(X\\) by summing over \\(y\\), so [ p_X(x) = y p{X,Y}(x,y) . ]\nWe can get the marginal PDF \\(f_X\\) of \\(X\\) by integrating over \\(y\\), so [ f_X(x) = {-}^f{X,Y}(x,y) , dy. ]\n\n\nTwo discrete random variables \\(X\\) and \\(Y\\) are independent if their PMFs satisfy [p_{X,Y}(x,y) = p_X(x),p_Y(y) .]\nTwo continuous random variables \\(X\\) and \\(Y\\) are independent if they have PDFs which satisfy [f_{X,Y}(x,y) = f_X(x),f_Y(y) .]\n\n\nThe conditional PMF of \\(Y\\) given \\(X\\) is defined by [ p_{Y X}(y x) = . ]\nThe conditional PDF of \\(Y\\) given \\(X\\) is defined by [ f_{Y X}(y x) = . ]\n\n\nBayes’ theorem states that [ p_{X Y}(x y) = . ]\nBayes’ theorem states that [ f_{X Y}(x y) = . ]\n\n\nThe expectation of a function of \\(X\\) and \\(Y\\) is given by the sum [ Eg(X,Y) = {x,y} g(x,y), p{X,Y}(x,y) . ]\nThe expectation of a function of \\(X\\) and \\(Y\\) is given by the integral [ Eg(X,Y) = {-}^{-}^g(x,y), f_{X,Y}(x,y) , dx , dy . ]\n\n\nThe covariance of \\(X\\) and \\(Y\\) is given by [ (X,Y) = E(X - _X)(Y - _Y) , ] and has a computational formula [ (X,Y) = EXY - _X _Y . ]\nThe covariance of \\(X\\) and \\(Y\\) is given by [ (X,Y) = E(X - _X)(Y - _Y) , ] and has a computational formula [ (X,Y) = EXY - _X _Y . ]\n\n\n\n\nConsider the pair of continuous random variable \\((X,Y)\\) with joint PDF [ f_{X,Y}(x,y) = (1 + x + y) ] and \\(f_{X,Y}(x,y) = 0\\) otherwise.\nWe get the marginal distribution for \\(X\\) by integrating over \\(y\\), so [ f_X(x) = _0^1 (1 + x + y) , dy = _0^1 = + 12x . ]\nWe can find the the conditional PDF for \\(Y\\) given \\(X = \\tfrac14\\). It is [ f_{YX}(y ) = = = + y . ]\nWe can calculate the covariance. First, the expectations are [ EX = _{-}^x, f_X(x) ,dx = _0^1 x( + 12x), dx = = ] and \\(\\mathbb EY = \\frac{13}{24}\\) also, by symmetry. Second, we have \\[\\begin{align*}\n\\mathbb EXY\n&= \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty xy\\, f_{X,Y}(x,y) \\, \\mathrm dx\\, \\mathrm dy \\\\\n&= \\int_0^1 \\int_0^1 xy \\, \\tfrac12(1 + x + y)\\, \\mathrm dx\\, \\mathrm dy \\\\\n&= \\int_0^1 \\left[ \\tfrac14 x^2y + \\tfrac16 x^3y + \\tfrac14 x^2y^2  \\right]_{x=0}^1 \\, \\mathrm dy\\\\\n&= \\int_0^1 \\big( \\tfrac14 y + \\tfrac16 y + \\tfrac14 y^2 \\big) \\, \\mathrm dy\\\\\n&= \\left[ \\tfrac18 y^2 + \\tfrac{1}{12}y^2 + \\tfrac{1}{12}y^3  \\right]_0^1 \\\\\n&= \\tfrac{7}{24} .\n\\end{align*}\\] So therefore, [ (X,Y) = EXY - _X _Y = - = - . ]"
  },
  {
    "objectID": "sections/L16-exponential-multi.html#summary-L17",
    "href": "sections/L16-exponential-multi.html#summary-L17",
    "title": "17  Exponential distribution and multiple continuous random variables",
    "section": "Summary",
    "text": "Summary\n\n\nThe exponential distribution has PDF \\(f(x) = \\lambda \\mathrm e^{-\\lambda x}\\), expectation \\(1/\\lambda\\), and variance \\(1/\\lambda^2\\).\nMost properties of multiple discrete random variables carry of to multiple continuous random variables. To get a marginal PDF from a joint PDF, we integrate (rather than sum) over the other variable."
  },
  {
    "objectID": "sections/L03-events.html#what-is-prob",
    "href": "sections/L03-events.html#what-is-prob",
    "title": "3  Sample spaces and events",
    "section": "3.1 What is probability?",
    "text": "3.1 What is probability?\nWe now begin the big central block of this module, on probability theory.\nProbability theory is the study of randomness. Probability, as an area of mathematics, is a fascinating subject in its own right. However, probability is particularly important due to its usefulness in applications – especially in statistics (the study of data), in finance, and in actuarial science (the study of insurance).\nProbability is well suited to modelling situations that involve randomness, uncertainty, or unpredictability. If we you want to predict the time of the next solar eclipse, a deterministic (that is, non-random) model based on physical laws will tell you when the sun, the moon, and the earth will be in the correct positions; but if you want to predict the weather tomorrow, or the price of a share of Apple stock next month, or the results of an election next year, you will need a probabilistic model that takes into account the uncertainty in the outcome. A probabilistic model could tell you the most likely outcome, or a range of the most probable outcomes.\nSo what do we mean when we talk about the “probability” of an event occurring? You might say that the probability of an event is a measure of “how likely” it is to occur, or what the “chance” of it occurring is.\nMore concretely, here are some interpretations of probability:\n\nSubjective (or Bayesian) probability: The probability of an event is the way someone expresses their degree of belief that the event will occur, based on their own judgement, and given the evidence they have seen. Their belief is measured on a scale from 0 to 1, from probabilities near 0 meaning they believe the event is very unlikely to occur to probabilities near 1 meaning they believe the event is very likely to occur.\n\nThis interpretation is philosophically sound, but a bit vague to be the basis for a mathematics module.\n\nClassical (or enumerative) probability: Suppose there are a finite number of equally likely outcomes. Then the probability of an event is the proportion of those outcomes that correspond to the event occurring. So when we say that a randomly dealt card has a probability \\(\\frac{1}{13}\\) of being an ace, this is because there are 52 cards of which 4 are aces, so the proportion of favourable outcomes is \\(\\frac{4}{52} = \\frac{1}{13}\\).\n\nThis interpretation is good for simple procedures like flipping a fair coin, rolling a dice, or dealing cards, where the “finite number of equally likely outcomes” assumption holds. But we want to be able to study more complicated situations, where some outcomes are more likely than others, or where infinitely many different outcomes are possible.\n\nFrequentist probability: In a repeated experiment, the probability of an event is its long-run frequency. That is, if we repeat an experiment a very large number of times, the probability of the event is (approximately) the proportion of the experiments in which the event occurs. So when we say a biased coin has probability 0.9 of landing heads, we mean that were we toss it 1000 times, we would expect to see very close to \\(0.9 \\times 1000 = 900\\) heads.\n\nThere are two problems with this. First, this doesn’t deal with events that can’t be repeated over and over again (like “What’s the probability that England win the 2022 World Cup?”). Second, to answer the question, “Yes, but how close to the probability should the proportion of occurrences be?”, you end up having to answer, “Well, it depends on the probability,” and you’ve got a circular definition.\n\nMathematical probability: We have a function that assigns to each event a number between 0 and 1, called its probability, and that function has to obey certain mathematical rules, called “axioms”.\n\nIt will not surprise you to learn that, in this mathematics course, we will take the “mathematical probability” approach. However, we will also learn useful things about the other approaches: we will see that classical probability is one special case of mathematical probability; we will see a result called the “law of large numbers” that says that the long-run frequency does indeed get closer and closer to the mathematical probability; and a result called “Bayes’ theorem” will advise a subjectivist on how to update her subjective beliefs when she sees new evidence."
  },
  {
    "objectID": "sections/L03-events.html#sample-events",
    "href": "sections/L03-events.html#sample-events",
    "title": "3  Sample spaces and events",
    "section": "3.2 Sample spaces and events",
    "text": "3.2 Sample spaces and events\n\nTaking the “mathematical probability” approach, we will want to give a formal mathematical definition of the probability of an event. But even before that, we need to give a formal mathematical definition of an event itself. Our setup will be this:\n\nThere is a set called the sample space, normally given the letter \\(\\Omega\\) (upper-case Omega), which is the set of all possible outcomes.\nAn element of the sample space \\(\\Omega\\) is a sample outcome, sometimes given the letter \\(\\omega\\) (lower-case omega), represents one of the possible outcomes.\nAn event is a set of sample outcomes; that is, a subset of the sample space \\(\\Omega\\). Events are often given letters like \\(A\\), \\(B\\), \\(C\\). We write \\(A \\subset \\Omega\\) to mean that \\(A\\) is an event in (or, equivalently, is a subset of) the sample space \\(\\Omega\\).\n\nThis will be easier to understand with some concrete examples. We write a set (such as a sample space or an event) by writing all the elements of that set inside curly brackets \\(\\{\\ \\}\\), separated by commas.\n\nExample 3.1 Suppose we toss a (possibly biased) coin, and record whether it lands heads or tails. Then our sample space is \\(\\Omega = \\{\\mathrm H, \\mathrm T\\}\\), where the sample outcome H denotes heads and the sample outcome T denotes tails.\nThe event that the coin lands heads is \\(\\{\\mathrm H\\}\\).\n\n\nExample 3.2 Suppose we roll a dice, and record the number rolled. Then our sample space is \\(\\Omega = \\{1,2,3,4,5,6\\}\\), where the sample outcome \\(1\\) corresponds to rolling a one, and so on.\nThe event “we roll an even number” is \\(\\{2,4,6\\}\\). The event “we roll at least a five” is \\(\\{5,6\\}\\).\n\n\nExample 3.3 Suppose we wish to count how many claims are made to an insurance company in a year. We could model this by taking the sample space \\(\\Omega\\) to be \\(\\mathbb Z_+ = \\{0, 1, 2, \\dots\\}\\), the set of all non-negative integers.\nThe event “the company receives less than 1000 claims” is \\(\\{0, 1, 2, \\dots, 998, 999\\}\\).\n\n\nExample 3.4 Suppose we want a computer to pick a random number between 0 and 1. We could model this by taking the sample space \\(\\Omega\\) to be the interval \\([0, 1]\\) of all real numbers between 0 and 1.\nThe event “the number is bigger than \\(\\frac12\\)” is the sub-interval \\((\\frac12, 1]\\) of all real numbers greater than \\(\\frac12\\) but no bigger than 1. The event “the first digit is a 7” is the sub-interval \\([0.7, 0.8)\\). The event “the random number is exactly \\(1/\\sqrt{2}\\)” is \\(\\{1/\\sqrt{2}\\}\\).\n\nIn the first two examples, the sample space \\(\\Omega\\) was finite. In third example, the sample space was infinite but “countably infinite”, in that it could be counted using the discrete values of the positive integers. Both of these were for counting discrete observations. In the fourth example, the sample space was infinite but “uncountably infinite”, in that it had a sliding scale or “continuum” of gradually varying measurements. This was for measuring continuous observations. This distinction will be important later in the course.\nFor any sample space \\(\\Omega\\), there are two special events that always exist. There’s \\(\\Omega\\) itself, the event containing all of the sample outcomes, which represents “something happens”. There’s also the empty set \\(\\varnothing\\), which contains none of the sample outcomes, which represents “nothing happens”. Common sense suggests that \\(\\Omega\\) should have probability 1, because something is bound to happen – this will later be one of our probability “axioms”. Common sense also suggests that \\(\\varnothing\\) should have probability 0, because it can’t be that nothing happens – this will not be one probability axioms, but we’ll show that it follows logically from the axioms we do choose."
  },
  {
    "objectID": "sections/L03-events.html#set-theory",
    "href": "sections/L03-events.html#set-theory",
    "title": "3  Sample spaces and events",
    "section": "3.3 Set theory",
    "text": "3.3 Set theory\n\nSince we’ve now defined events as being sets – specifically, subsets of the sample space \\(\\Omega\\) – it will be useful to mention a little set basic theory here.\nFirst, there are ways we can build new sets (or events) out of old. It’s fine to just read the words and look at the pictures for these definitions, but those who want to read the equations too will need to know this:\n\n\\(\\omega \\in A\\) means “\\(\\omega\\) is in \\(A\\)” or “\\(\\omega\\) is an element of \\(A\\)”, while \\(\\omega \\not\\in A\\) means the opposite, that \\(\\omega\\) is not in \\(A\\);\na colon \\(:\\) in the middle of set notation should be read as “such that”;\nso \\(\\{\\omega \\in \\Omega : \\text{fact about $\\omega$}\\}\\) should be read as “the set of sample points \\(\\omega\\) in the sample space \\(\\Omega\\) such that the fact is true”.\n\n\nDefinition 3.1 Consider a sample space \\(\\Omega\\), and let \\(A\\) and \\(B\\) be events in that sample space.\n\n\n\nNOT: The complement of \\(A\\), written \\(A^\\mathsf{c}\\) (and said “\\(A\\) complement” or “not \\(A\\)”), is the set of sample points not in \\(A\\); that is [ A^= {: A } . ] This represents the event that \\(A\\) does not occur.\nAND: The intersection of \\(A\\) and \\(B\\), written \\(A \\cap B\\) (and said “\\(A\\) intersect \\(B\\)” or “\\(A\\) and \\(B\\)”) is the set of sample points in both \\(A\\) and \\(B\\); that is,\n[ A B = {: A B } . ] This represents the event that both \\(A\\) and \\(B\\) occur.\nOR: The union of \\(A\\) and \\(B\\), written \\(A \\cup B\\) (and said “\\(A\\) union \\(B\\)” or “\\(A\\) or \\(B\\)”) is the set of sample points in \\(A\\) or in \\(B\\); that is, [ A B = {: A B } . ] This represents the event that \\(A\\) occurs or \\(B\\) occurs. (In mathematics, “or” includes “both”, so a sample outcome in both \\(A\\) and \\(B\\) is in \\(A\\cup B\\) too.)\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 3.5 Suppose we are rolling a dice, so our sample space is \\(\\Omega = \\{1,2,3,4,5,6\\}\\). Let \\(A = \\{2,4,6\\}\\) be the event that we roll and even number, and let \\(B = \\{5,6\\}\\) be the event that we roll at least a 5. Then \\[\\begin{align*}\nA^\\mathsf{c}&= \\{1,3,5\\} = \\{\\text{roll an odd number}\\} ,\\\\\nA \\cap B &= \\{6\\} = \\{\\text{roll a 6}\\} ,\\\\\nA \\cup B &= \\{2,4,5,6\\} .\n\\end{align*}\\]\n\nAn important case is when two events \\(A, B\\) cannot happen at the same time; that is, \\(A \\cap B = \\varnothing\\) (“\\(A\\) intersect \\(B\\) is the empty set”). In this case, we say that \\(A\\) and \\(B\\) are disjoint or mutually exclusive. For example, when \\(\\Omega\\) is a deck of cards, then \\(A = \\{\\text{the card is a spade}\\}\\) and \\(B = \\{\\text{the card is red}\\}\\) are disjoint, because a card cannot be both a spade (a black suit) and red.\nYou might think that if two events are disjoint, then it would be reasonable to find the probability of their union – that is, the probability that one (and, by necessity, only one) of them happens – you can just add the two separate probabilities together. This will be another of our “axioms” of probability.\nThere are a few rules about ways you can combine the complement, intersection and union operations. These are ways of building new events from old. \n\nThe double complement law tells us that not-not-\\(A\\) is the same as \\(A\\): [ (A)= A .] This says that if it’s not “not-raining”, then it’s raining!\nThe distributive laws tells us we can “multiply out of the brackets” with sets: \\[\\begin{align*}\nA \\cap (B \\cup C) &= (A \\cap B) \\cup (A \\cap C) ,\\\\\nA \\cup (B \\cap C) &= (A \\cup B) \\cap (A \\cup C) .\n\\end{align*}\\] The first says that if you are eating a burger with fries or salad, then you’re eating a burger with fries or eating a burger with salad. The second is a bit less intuitive, I find, but it’s clear that if \\(A\\) is true then the first of each of the terms on the right is true, while if both \\(B\\) and \\(C\\) are true then the second of each of the terms on the right is true.\nDe Morgan’s laws tell us how complements interact with intersection/unions: \\[\\begin{align*}\n(A \\cap B)^\\mathsf{c}&= A^\\mathsf{c}\\cup B^\\mathsf{c}\\\\\n(A \\cup B)^\\mathsf{c}&= A^\\mathsf{c}\\cap B^\\mathsf{c}\n\\end{align*}\\] The first of these says that if it’s not a Monday in October, then either it’s not Monday or it’s not October (or both). The second says that if a maths lecture is not “useful or fun”, then it’s not useful and it’s not fun. (Augustus De Morgan was a British mathematician of the 19th century who did important work in logic.)\n\nFor this module, these mostly count as “common sense” – but if you ever do need to prove one of these statements (or a similar one), one way is to use a Venn diagram.\nLet’s prove the second distributive law, \\[   A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C) , \\] with a Venn diagram as an example.\nWe can build the left-hand side of the law as:\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\nThe left-hand figure is \\(\\color{orange}{A}\\), the middle figure is \\(\\color{purple}{B\\cap C}\\), and the right-hand figure is union of these, \\(A\\cup (B\\cap C)\\).\nThen for the right-hand side of the law, we have:\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nThe left-hand figure is \\(\\color{orange}{A} \\cup \\color{blue}{B}\\), the middle figure is \\(\\color{orange}{A}\\cup \\color{red}{C}\\), and the right-hand figure is intersection of these, \\((A\\cup B)\\cap (A\\cup C)\\).\nWe see that the areas shaded in two right-hand figures are the same, so it is indeed the case that \\(A\\cup (B\\cap C) = (A\\cup B)\\cap (A\\cup C)\\)."
  },
  {
    "objectID": "sections/L03-events.html#summary-L03",
    "href": "sections/L03-events.html#summary-L03",
    "title": "3  Sample spaces and events",
    "section": "Summary",
    "text": "Summary\n\n\nA sample space \\(\\Omega\\) is a set representing all possible sample outcomes.\nAn event is a subset of \\(\\Omega\\).\nFor events \\(A\\) and \\(B\\), we also have the complement “not \\(A\\)” \\(A^\\mathsf{c}\\), the intersection “\\(A\\) and \\(B\\)” \\(A \\cap B\\), and the union “\\(A\\) or \\(B\\)” \\(A \\cup B\\)."
  },
  {
    "objectID": "sections/L04-probability.html#axioms",
    "href": "sections/L04-probability.html#axioms",
    "title": "4  Probability",
    "section": "4.1 Probability axioms",
    "text": "4.1 Probability axioms\n\nRecall that, in this mathematics course, the probability of an event will be a real number that satisfies certain properties, which we call axioms.\n\nLet \\(\\Omega\\) be a sample space. A probability measure on \\(\\Omega\\) is a function \\(\\mathbb P\\) that assigns to each event \\(A \\subset \\Omega\\) a real number \\(\\mathbb P(A)\\), called the probability of \\(A\\), and that satisfies the following three axioms:\n\n\\(\\mathbb P(A) \\geq 0\\) for all events \\(A \\subset \\Omega\\);\n\\(\\mathbb P(\\Omega) = 1\\);\nif \\(A_1, A_2, \\dots\\) is a finite or infinite sequence of disjoint events, then [ P(A_1 A_2 ) = P(A_1) + P(A_2) + . ]\n\nThe sample space \\(\\Omega\\) together with the probability measure \\(\\mathbb P\\) are called a probability space.\n\nAxiom 1 says that all probabilities are non-negative numbers. Axiom 2 says the probability that something happens is 1. Axiom 3 says that for disjoint events the probability that one of them happens is the sum of the individual probabilities. (Those who like their mathematical statements very precise should note that an infinite sequence in Axiom 3 must be “countable”; that is, indexed by the natural numbers \\(1, 2, 3. \\dots\\).)\nThese axioms of probability (and our later results that follow from them) were first written down by the Russian mathematician Andrey Nikolaevich Kolmogorov in 1933. This marked the point from when probability theory could now be considered a proper branch of mathematics – just as legitimate as geometry or number theory – and not just a past-time that can be useful to help gamblers calculate their odds. I always find it surprising that the axioms of probability are less than 90 years old!\nThere are other properties that it seems natural that a probability measure should have aside from the axioms – for example, that \\(\\mathbb P(A) \\leq 1\\) for all events \\(A\\). But we will show shortly that other properties can be proven just by starting from the three axioms.\nBut first, let’s see some examples.\n\nSuppose we wish to model tossing an biased coin the is heads with probability \\(p\\), where \\(0 \\leq p \\leq 1\\).\nOur probability space is \\(\\Omega = \\{\\text{H}, \\text{T}\\}\\). The probability measure is given by \\[\\begin{align*}\n   \\mathbb P(\\varnothing) &= 0  &  \\mathbb P(\\{\\text{H}\\}) &= p \\\\\n   \\mathbb P(\\{\\text{T}\\}) &= 1 - p  &  \\mathbb P(\\{\\text{H},\\text{T}\\})  &= 1 .\n\\end{align*}\\]\nLet’s check that the axioms hold:\n\nSince \\(0 \\leq p \\leq 1\\), all the probabilities are greater than or equal to 0.\nIt is indeed the case that \\(\\mathbb P(\\Omega) = \\mathbb P(\\{\\text{H},\\text{T}\\}) = 1\\).\nThe only nontrivial disjoint union to check is \\(\\{\\text{H}\\} \\cup \\{\\text{T}\\} = \\{\\text{H},\\text{T}\\}\\), where we see that [ P({}) + P({}) = p + (1 - p) = 1 = P({,}) , ] as required.\n\n\n\nSuppose we wish to model rolling a dice.\nOur sample space is \\(\\{1,2,3,4,5,6\\}\\). The probability measure is given by [ P(A) = , ] where \\(|A|\\) is the number of sample outcomes in \\(A\\).\nSo, for example, the probability of rolling an even number is [ P({2,4,6}) = = . ]\n\nThe dice rolling is a particular case of the “classical probability” of equally likely outcomes. We’ll look at this more in the next lecture, and prove that the classical probability measure does indeed satisfy the axioms"
  },
  {
    "objectID": "sections/L04-probability.html#prob-properties",
    "href": "sections/L04-probability.html#prob-properties",
    "title": "4  Probability",
    "section": "4.2 Properties of probability",
    "text": "4.2 Properties of probability\n\nThe axioms of Definition @ref(def:axioms) only gave us some of the properties that we would like a probability measure to have. Our task now (in this subsection and the next) is to carefully prove how these other properties follow from just those axioms. In particular, we’re not allowed to make claims that merely “seem likely to be true” or “are common sense” – we can only use the three axioms together with strict logical deductions and nothing else.\n\nLet \\(\\Omega\\) be a sample space with a probability measure \\(\\mathbb P\\). Then we have the following:\n\n\\(\\mathbb P(\\varnothing) = 0\\).\n\\(\\mathbb P(A^\\comp) = 1 - \\mathbb P(A)\\) for all events \\(A \\subset \\Omega\\).\nFor events \\(A\\) and \\(B\\) with \\(B \\subset A\\), we have \\(\\mathbb P(B) \\leq \\mathbb P(A)\\).\n\\(0 \\leq \\mathbb P(A) \\leq 1\\) for all events \\(A \\subset \\Omega\\).\n\n\nImportantly, the second result here tells us how to deal with complements or “not” events: the probability of \\(A\\) not happening is 1 minus the probability it does happen. This is often very useful.\n\nProof. The key with most of these “prove from the axioms” problems is to think of a way to write the relevant events as part of a disjoint union, then use Axiom 3. Statements 1 and 2 are exercises for you on Problem Sheet 2. We’ll start with the third statement.\nHere, since \\(B\\) is a subset of \\(A\\), meaning that \\(B\\) is entirely inside \\(A\\).\n\n\n\n\n\n\n\n\n\nIt would be useful to write \\(A\\) as a disjoint union of \\(\\color{orange}B\\) and “the bit of \\(A\\) that isn’t in \\(B\\)”. That is, we have the disjoint union [ A = B () .]\n\n\n\n\n\n\n\n\n\nApplying Axiom 3 to this disjoint union gives [ P(A) = P(B) + P(A B^) . ]\nWe’re happy to see the term on the left-hand side and the first term on the right-hand side. But what about the awkward \\(\\mathbb P(A \\cap B^\\comp)\\)? Well, by Axiom 1, we know that the probability of any event is greater than or equal to 0, so in particular. \\(\\mathbb P(A \\cap B^\\comp) \\geq 0\\). Hence [ P(A) P(B) + 0 = P(B) , ] and we are done with the third statement.\nFor the fourth statement, we have \\(\\mathbb P(A) \\geq 0\\) directly from Axiom 1, so only need to show that \\(\\mathbb P(A) \\leq 1\\). We can do this using the third statement of this theorem. For any event \\(A\\) we have \\(A \\subset \\Omega\\), so the third statement tells us that \\(\\mathbb P(A) \\leq \\mathbb P(\\Omega)\\). But Axiom 2 tells us that \\(\\mathbb P(\\Omega) = 1\\), so \\(\\mathbb P(A) \\leq 1\\) and we are done."
  },
  {
    "objectID": "sections/L04-probability.html#addition",
    "href": "sections/L04-probability.html#addition",
    "title": "4  Probability",
    "section": "4.3 Addition rules for unions",
    "text": "4.3 Addition rules for unions\n\nIf we have two or more events, we’d like to work out the probability of their union; that is, the probability that at least one of them occurs.\nWe already have an addition rule for disjoint unions.\n\nLet \\(A, B \\subset \\Omega\\) be two disjoint events. Then [ P(A B) = P(A) + P(B) . ]\n\n\nProof. In Axiom 3, take the finite sequence \\(A_1 = A\\), \\(A_2 = B\\).\n\nBut what about if \\(A\\) and \\(B\\) are not disjoint? Then we have the following.\n\nLet \\(A, B \\subset \\Omega\\) be two events. Then [ P(A B) = P(A) + P(B) - P(A B) . ]\n\nYou may have seen this result before. You’ve perhaps justified it by saying something like this: “We can add the two probabilities together, except now we’ve double-counted the overlap, so we have to take the probability of that away.” Maybe you drew a Venn diagram. That’s OK as a way to remember the result – but this is a proper university mathematics course, so we have to carefully prove it starting from just the axioms and nothing else.\n(The following proof has been updated to match how I taught it in Wednesday’s lecture.)\n\nProof. The problem here is that \\(A\\) and \\(B\\) are not (in general) disjoint, so we can’t apply Axiom 3.\n\n\n\n\n\n\n\n\n\nInstead, let’s split this up into the three disjoint bits: “\\(A\\) but not \\(B\\)” \\(\\color{red}{A \\cap B^\\comp}\\), “\\(B\\) but not \\(A\\)” \\(\\color{blue}{B \\cap A^\\comp}\\), and “both” \\(\\color{green}{A \\cap B}\\).\n\n\n\n\n\n\n\n\n\nNow we can write \\(A\\), \\(B\\) and \\(A \\cup B\\) in terms of these disjoint bits. \\[\\begin{align}\nA &= (\\color{red}{A \\cap B^\\mathsf{c}}) \\cup (\\color{green}{A \\cap B}) \\\\\nB &= (\\color{blue}{B \\cap A^\\mathsf{c}}) \\cup (\\color{green}{A \\cap B}) \\\\\nA \\cup B &= (\\color{red}{A \\cap B^\\mathsf{c}}) \\cup (\\color{blue}{B \\cap A^\\mathsf{c}}) \\cup (\\color{green}{A \\cap B}),\n\\end{align}\\] with all the unions on the right-hand side being disjoint. Applying Axiom 3 to them all gives \\[\\begin{align}\n\\mathbb P(A) &= \\mathbb P(A \\cap B^\\mathsf{c}) + \\mathbb P(A \\cap B) (\\#eq:un1)  \\\\\n\\mathbb P(B) &= \\mathbb P(B \\cap A^\\mathsf{c}) + \\mathbb P(A \\cap B)  (\\#eq:un2) \\\\\n\\mathbb P(A \\cup B) &= \\mathbb P(A \\cap B^\\mathsf{c}) + \\mathbb P(B \\cap A^\\mathsf{c}) + \\mathbb P(A \\cap B) . (\\#eq:un3)\n\\end{align}\\] Here, @ref(eq:un3) is looking good, but we need to get rid of the awkward \\(\\mathbb P(A \\cap B^\\mathsf{c})\\) and \\(\\mathbb P(B \\cap A^\\mathsf{c})\\) terms. We can do that be rearranging @ref(eq:un1) and @ref(eq:un2) to get \\[\\begin{align}\n\\mathbb P(A \\cap B^\\mathsf{c}) &= \\mathbb P(A) - \\mathbb P(A \\cap B) \\\\\n\\mathbb P(B \\cap A^\\mathsf{c}) &= \\mathbb P(B) - \\mathbb P(A \\cap B) .\n\\end{align}\\] Substituting these into @ref(eq:un3) gives \\[\\begin{align}\n\\mathbb P(A \\cup B) &= \\mathbb P(A) - \\mathbb P(A \\cap B) + \\mathbb P(B) - \\mathbb P(A \\cap B) + \\mathbb P(A \\cap B) \\\\\n  &= \\mathbb P(A)+ \\mathbb P(B) - \\mathbb P(A \\cap B) ,\n\\end{align}\\] as required.\n\n\n\nConsider picking a card from a deck at random, with \\(\\mathbb P(A) = |A|/52\\). What’s the probability the card is a spade or an ace?\nIt is possible to just to work this out directly. But let’s use our addition law for unions.\nWe have \\(\\mathbb P(\\text{spade}) = \\frac{13}{52}\\) and \\(\\mathbb P(\\text{ace}) = \\frac{4}{52}\\). So we have [ P() = + - P() . ] But \\(\\mathbb P(\\text{spade and ace})\\) is the probability of picking the ace of spades, which is \\(\\frac{1}{52}\\). Therefore [ P() = + - = = . ]"
  },
  {
    "objectID": "sections/L04-probability.html#summary-L04",
    "href": "sections/L04-probability.html#summary-L04",
    "title": "4  Probability",
    "section": "Summary",
    "text": "Summary\n\n\nThe axioms of probability are (1) \\(\\mathbb P(A) \\geq 0\\); (2) \\(\\mathbb P(\\Omega) = 1\\); and (3) that for disjoint events \\(A_1, A_2, \\dots\\), we have \\(\\mathbb P(A_1 \\cup A_2 \\cup \\cdots) = \\mathbb P(A_1) + \\mathbb P(A_2) + \\cdots\\).\nOther properties can be proven from these axioms, like the complement rule \\(\\mathbb P(A^\\comp) = 1 - \\mathbb P(A)\\), and the addition rule for unions \\(\\mathbb P(A \\cup B) = \\mathbb P(A) + \\mathbb P(B) - \\mathbb P(A \\cap B)\\)."
  },
  {
    "objectID": "R/R.html#r-work",
    "href": "R/R.html#r-work",
    "title": "R Worksheets",
    "section": "R worksheets",
    "text": "R worksheets\nEach week there will be an R worksheet to work through in your own time. I recommend spending about one hour on each worksheet, plus one extra hour for worksheets with assessed questions, for checking and submitting your solutions.\n\n\n\nWeek\nWorksheet\nDeadline for assessed work\n\n\n\n\n1\nR basics (Solutions)\n—\n\n\n2\nVectors\n—\n\n\n3\nData in R\nMonday 24 October (Week 4)\n\n\n4\nPlots I: Making plots\n—\n\n\n5\nPlots II: Making plots better\nMonday 7 November (Week 6)\n\n\n6\nRMarkdown (optional) [Rmd]\n—\n\n\n7\nDiscrete distributions [Rmd]\nMonday 21 November (Week 8)\n\n\n8\nDiscrete random variables [Rmd]\n—\n\n\n9\nNormal distribution [Rmd]\nMonday 5 December (Week 10)\n\n\n10\nLaw of large numbers [Rmd]\n—\n\n\n11\nRecap\nThursday 15 December (Week 11)"
  },
  {
    "objectID": "R/R.html#about-r",
    "href": "R/R.html#about-r",
    "title": "R Worksheets",
    "section": "About R and RStudio",
    "text": "About R and RStudio\n\nR is a programming language that is particularly useful for working with probability and statistics. R is very widely used in universities and increasingly widely used in industry. Learning to use R is a mandatory part of this module, and exercises requiring use of R make up at least 15% of your module mark. Many other statistics-related modules at the University also use R.\nRStudio is a program that gives a convenient way to work with the language R. RStudio is the most common way to use the language R, and learning to use RStudio is strongly recommended.\n\nR and RStudio are free/open-source software."
  },
  {
    "objectID": "R/R.html#r-access",
    "href": "R/R.html#r-access",
    "title": "R Worksheets",
    "section": "How to access R and RStudio",
    "text": "How to access R and RStudio\nThere are a few ways you can access R and RStudio.\nFirst, you can install R and RStudio on your own computer. Students who have their own computer (with administration and installation rights) usually find this the most convenient way use R.\nWhen you install R and RStudio, it’s important that you install R (the programming language) first, and only install RStudio (the program to use R) after R has already been installed. This ensures that RStudio can “find” R on your computer.\n\nFirst, install R. Go to the Comprehensive R Archive Network (CRAN) and follow the instructions:\n\nWindows: Click “Download R for Windows”, then “Install R for the first time”. The main link at the top should be to download the most recent version of R.\nMac: Click Download R for macOS, and then download the relevant PKG file. (For typically older Intel-based Macbooks, you must use the “Intel 64-bit build”; for post-November 2020 M1 or M2-based “Apple silicon” Macbooks, the “Apple silicon arm64 build” may be slightly faster.)\n\nAfter R is installed, then install RStudio. Go to the Download page at RStudio.com and follow the instructions. You want “RStudio Desktop”, and you want the free version.\n\nIf you have difficulty installing R, come along to the R troubleshooting drop-in session in Week 2 and bring your computer with you (if it’s sufficiently portable), and we’ll do our best to help.\nSecond, you can use R and RStudio on University computers. All University computers have access to R and RStudio, via the AppsAnywhere service. First, launch R via AppsAnywhere (at the time of writing, it’s confusingly named “Cran R 4.2.0 x64”). You can then close the program that opens. Then launch RStudio (“Rstudio 2022”), also via AppsAnywhere. (You can decline any updates that are suggested.)\nThe R drop-in sessions take place in computer rooms, so if you have problems accessing R and RStudio on University computers, you can get help at the drop-in sessions too.\nThird, you can use the RStudio Cloud. The RStudio Cloud is a cloud-hosted “Google Docs for R” that you can use through your web browser, without having to install anything. You can get 25 hours per month for free, which should be plenty for this module, or pay for more.\nIf you have access to a computer on which you can’t install software, such as some Chromebooks or tablet computers, or if you’re borrowing a friend’s laptop, the RStudio Cloud can be a convenient solution.\nUpdate: If you have an Intel-based Chromebook, then we have had success installing R and RStudio using these (rather complicated) instructions, although you may still find it more convenient just to use the RStudio Cloud."
  },
  {
    "objectID": "R/R.html#troubleshooting",
    "href": "R/R.html#troubleshooting",
    "title": "R Worksheets",
    "section": "R troubleshooting drop-in sessions",
    "text": "R troubleshooting drop-in sessions\nYou will learn to use R by working through the R Worksheets. Learning to use a programming language is different from learning mathematics: you should expect to regularly get frustrated and annoyed when the computer seems to refuse to do what you want it to (but also occasionally experience the joy of getting it right!). This is a normal part of learning.\nHowever, many students find getting with started with R in the first few weeks particularly difficult. Also, sometimes students have problems installing R and RStudio on their own computers. To help with this, we have organised optional R troubleshooting drop-in sessions in Weeks 2 and 3. Check your timetable for details – they are probably listed as “computer practicals”."
  },
  {
    "objectID": "sections/L01-stats.html#what-is-eda",
    "href": "sections/L01-stats.html#what-is-eda",
    "title": "1  Summary statistics",
    "section": "1.1 What is EDA?",
    "text": "1.1 What is EDA?\nStatistics is the study of data. Exploratory data analysis (or EDA, for short) is the part of statistics concerned with taking a “first look” at some data. Later, toward the end of this course, we will see more detailed and complex ways of building models for data, and in MATH1712 Probability and Statistics II (for those who take it) you will see many other statistical techniques – in particular, ways of testing formal hypotheses for data. But here we’re just interested in first impressions and brief summaries.\nIn this section, we will concentrate on two aspects of EDA:\n\nSummary statistics: That is, calculating numbers that briefly summarise the data. A summary statistic might tell us what “central” or “typical” values of the data are, how spread out the data is, or about the relationship between two different variables.\nData visualisation: Drawing a picture based on the data is an another way to show the shape (centrality and spread) of data, or the relationship between different variables.\n\nEven before calculating summary statistics or drawing a plot, however, there are other questions it is important to ask about the data:\n\nWhat is the data? What variables have been measured? How were they measured? How many datapoints are there? What is the possible range of responses?\nHow was the data collected? Was data collected on the whole population or just a smaller sample? If a sample: How was that sample chosen? Is that sample representative of the population?\nAre there any outliers? “Outliers” are datapoints that seem to be very different from the other datapoints – for example, are much larger or much smaller than the others. Each outlier should be investigated to seek the reason for it. Perhaps it is a genuine-but-unusual datapoint (which is useful for understanding the extremes of the data), or perhaps there is an extraordinary explanation (a measurement or recording error, for example) meaning the data is not relevant. Once the reason for an outlier is understood, it then might be appropriate to exclude it from analysis (for example, the incorrectly recorded measurement). It’s usually bad practice to exclude an outlier merely for being an outlier before understanding what caused it.\nEthical questions: Was the data collected ethically and, where necessary, with the informed consent of the subjects? Has it been stored properly? Are their privacy issues with the collection and storage of the data? What ethical issues should be considered before publishing (or not publishing) results of the analysis? Should the data be kept confidential, or should it be openly shared with other researchers for the betterment of science?"
  },
  {
    "objectID": "sections/L01-stats.html#what-is-R",
    "href": "sections/L01-stats.html#what-is-R",
    "title": "1  Summary statistics",
    "section": "1.2 What is R?",
    "text": "1.2 What is R?\nR is a programming language that is particularly good at working with probability and statistics. A convenient way to use the language R is through the program RStudio. An important part of this module is learning to use R, by completing weekly worksheets – you can read more in the R section of these notes.\nR can easily and quickly perform all the calculations and draw all the plots in this section of notes on exploratory data analysis. In this text, we’ll show the relevant R code. Code will appear like this:\n\ndata <- c(4, 7, 6, 7, 4, 5, 5)\nmean(data)\n\n[1] 5.428571\n\n\nHere, the code in the first shaded box is the R commands that are typed into RStudio, which you can type in next to the > arrow in the RStudio “console”. The numerical answers that R returns are shown here in the second unshaded box next to a double hashsign ##. The [1] can be ignored (this is just R’s way of saying that this is the first part of the answer – but the answer here only has one part anyway). Plots produced by R are displayed in these notes as pictures.\nMost importantly for now, you are not expected to understand the R code in this section yet. The code is included so that, in the future, as you work through the R worksheets week by week, you can look back at the code in the section, and it will start to make sense. By the time you have finished R Worksheet 5 in week 5, you should be able understand most of the R code in this section."
  },
  {
    "objectID": "sections/L01-stats.html#stat-central",
    "href": "sections/L01-stats.html#stat-central",
    "title": "1  Summary statistics",
    "section": "1.3 Statistics of centrality",
    "text": "1.3 Statistics of centrality\n\nSuppose we have collected some data on a certain variable. We will assume here that we have \\(n\\) datapoints, each of which is a single real number. We can write this data as a vector [ x = (x_1, x_2, , x_n) . ]\nA statistic is a calculation from the data \\(\\mathbf x\\), which is (usually) also a real number. In this section we will look at two types of “summary statistics”, which are statistics that we feel will give us useful information about the data.\nWe’ll look here at two types of summary statistic:\n\nStatistics of centrality, which tell us where the “middle” of the data is.\nStatistics of spread, which tell us how far the data typically spreads out from that middle.\n\nSome measures of centrality are the following.\n\nConsider some real-valued data \\(\\mathbf x = (x_1, x_2, \\dots, x_n)\\).\n\nThe mode is the most common value of \\(x_i\\). (If there are multiple joint-most common values, they are all modes.)\nSuppose the data is ordered as \\(x_1 \\leq x_2 \\leq \\cdots \\leq x_n\\). Then the median is the central value in the ordered list. If \\(n\\) is odd, this is \\(x_{(n+1)/2}\\); if \\(n\\) is even, we normally take halfway between the two central points, \\(\\frac12(x_{n/2}+x_{n/2 + 1})\\).\nThe mean \\(\\bar x\\) is [ x = (x_1 + x_2 + + x_n) = 1n _{i=1}^n x_i . ]\n\n\n(In that last expression, we’ve made use of Sigma notation to write down the sum.)\n\nSome packets of Skittles (a small fruit-flavoured sweet) were opened, and the number of Skittles in each packet counted. There were 13 packets, and the number of sweets (sorted from smallest to largest) were: [ 59,  59,  59,  59,  60,  60,  60,  61,  62,  62,  62,  63,  63 .] The mode is 59, because there were 4 packets containing 59 sweets; more than any other number. Since there are \\(n = 13\\) packets, the middle packet is number \\(i = 7\\), so the median is \\(x_7 = 60\\). The mean is [ x = (59 + 59 + + 63) = = 60.7 .]\n\nThe median is one example of a “quantile” of the data. Suppose our data is increasing order again. For \\(0 \\leq \\alpha \\leq 1\\), the \\(\\alpha\\)-quantile \\(q(\\alpha)\\) of the data is the datapoint \\(\\alpha\\) of the way along the list. Generally, \\(q(\\alpha)\\) is equal to \\(x_{1+\\alpha(n-1)}\\) when \\(1+\\alpha(n-1)\\) is an integer. (If \\(1+\\alpha(n-1)\\) isn’t an integer, there are various conventions of how to choose that we won’t go into here. R has nine different settings for choosing quantiles! – we will always just use R’s default choice.)\n\nThe median is the \\(\\frac12\\)-quantile \\(q(\\frac12)\\), which is \\(q(\\frac12) = x_7 = 60\\) for this data.\nThe minimum is the 0-quantile \\(q(0)\\), which is \\(q(0) = x_1 = 59\\) for this data.\nThe maximum is the 1-quantile \\(q(1)\\), which is \\(q(1) = x_{13} = 63\\) for this data\nThe lower quartile (that’s “quartile”, as in “quarter” – not “quantile”) is the \\(\\frac14\\)-quantile \\(q(\\frac14)\\), which is \\(q(\\frac14) = x_4 = 59\\) for this data.\nThe upper quartile is the \\(\\frac34\\)-quantile \\(q(\\frac34)\\), which is \\(q(\\frac34) = x_{10} = 62\\) for this data.\n\nThe following R code reads in some data which has the daily average temperature in Leeds in 2020, divided into months. We can find, for example, the mean October temperature or the lower quartile of the July temperature.\n\ntemperature <- read.csv(\"https://mpaldridge.github.io/math1710/data/temperature.csv\")\njul <- temperature[temperature$month == \"jul\", ]\noct <- temperature[temperature$month == \"oct\", ]\n\nmean(oct$temp)\n\n[1] 11.93548\n\nquantile(jul$temp, probs = 1 / 4)\n\n25% \n 15"
  },
  {
    "objectID": "sections/L01-stats.html#stat-spread",
    "href": "sections/L01-stats.html#stat-spread",
    "title": "1  Summary statistics",
    "section": "1.4 Statistics of spread",
    "text": "1.4 Statistics of spread\nSome measures of spread are:\n\nThe number of distinct observations is precisely that: the number of different datapoints we have after removing any repeats.\nThe interquartile range is the difference between the upper and lower quartiles \\(\\text{IQR} = q(\\frac34) - q(\\frac14)\\).\nThe sample variance is [ s^2_x = ((x_1 - x)^2 + + (x_n - x)^2 ) = _{i=1}^n (x_i - x)^2 , ] where \\(\\bar x\\) is the sample mean from before. The standard deviation \\(s_x = \\sqrt{s^2_x}\\) is the square-root of the sample variance.\n\nThe formula we’ve given for sample variance is sometimes called the “definitional formula”, as it’s the formula used to define the sample variance. We can rearrange that formula as follows: \\[\\begin{align*}\n  s^2_x &= \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar x)^2 \\\\\n      &= \\frac{1}{n-1} \\sum_{i=1}^n (x_i^2 - 2x_i\\bar x + \\bar x^2) \\\\\n      &= \\frac{1}{n-1}\\left(\\sum_{i=1}^nx_i^2 - \\sum_{i=1}^n 2x_i\\bar x + \\sum_{i=1}^n\\bar x^2 \\right) \\\\\n      &= \\frac{1}{n-1} \\left(\\sum_{i=1}^n x_i^2 - 2\\bar x \\sum_{i=1}^n x_i + \\bar x^2 \\sum_{i=1}^n 1 \\right) \\\\\n      &= \\frac{1}{n-1} \\left(\\sum_{i=1}^n x_i^2 - 2n\\bar x^2 + n\\bar x^2 \\right) \\\\\n      &= \\frac{1}{n-1} \\left(\\sum_{i=1}^n x_i^2 -  n\\bar x^2 \\right) .\n\\end{align*}\\] Here, the first line is the definitional formula; the second line is from expanding out the bracket; the third line is taking the sum term-by-term; the fourth line takes any constants (things not involving \\(i\\)) outside the sums; the fifth line uses \\(\\sum_{i=1}^n x_i = n\\bar x\\), from the definition of the mean, and \\(\\sum_{i=1}^n 1 = 1 + 1 + \\cdots 1 = n\\); and the sixth line simplifies the final two terms.\nThis has left us with [ s^2_x = (_{i=1}^n x_i^2 - nx^2 ) . ] This is sometimes called the “computational formula”; this is because it usually takes fewer presses of calculator buttons to compute the sample variance with this formula rather than the definitional formula. (But make sure you keep enough decimal points in \\(\\bar x^2\\).)\nGoing back to our weather data in R, we can find the sample variance of the October weather or the interquartile range of the July weather.\n\nvar(oct$temp)\n\n[1] 2.862366\n\nIQR(jul$temp)\n\n[1] 3"
  },
  {
    "objectID": "sections/L01-stats.html#summary-01",
    "href": "sections/L01-stats.html#summary-01",
    "title": "1  Summary statistics",
    "section": "Summary",
    "text": "Summary\n\n\nExploratory data analysis is about taking a first look at data.\nSummary statistics are numbers calculated from data that give us useful information about the data.\nSummary statistics that measure the centre of the data include the mode, median, and mean.\nSummary statistics that measure the spread of the data include the number of distinct outcomes, the interquartile range, and the sample variance."
  },
  {
    "objectID": "sections/L02-dataviz.html#boxplots",
    "href": "sections/L02-dataviz.html#boxplots",
    "title": "2  Data visualisations",
    "section": "2.1 Boxplots",
    "text": "2.1 Boxplots\nA boxplot is a useful way to illustrate numerical data. It can be easier to tell the difference between different data sets “by eye” when looking at a boxplot, rather than examining raw summary statistics.\nA boxplot is drawn as follows:\n\nThe vertical axis represents the data values.\nDraw a box from the lower quartile \\(q(\\frac14)\\) to the median \\(q(\\frac12)\\).\nDraw another box on top of this from the median \\(q(\\frac12)\\) to the upper quartile \\(q(\\frac34)\\). Note that size of these two boxes put together is the interquartile range.\nDecide which datapoints are outliers, and plot these with circles. (The R default is that any data point less than \\(q(\\frac14) - 1.5 \\times \\text{IQR}\\) or greater than \\(q(\\frac34) + 1.5 \\times \\text{IQR}\\) is an outlier.)\nOut from the two previous boxes, draw “whiskers” to the minimum and maximum non-outlier datapoints.\n\n\n\n\n\n\n\n\n\n\nWhen we have multiple datasets, drawing boxplots next to each other can help us to compare the datasets. Here are two boxplots from the July and October temperature data we used in the last lecture. What do you conclude about the data from these boxplots?\n\ntemperature <- read.csv(\"https://mpaldridge.github.io/math1710/data/temperature.csv\")\njul <- temperature[temperature$month == \"jul\", ]\noct <- temperature[temperature$month == \"oct\", ]\n\nboxplot(jul$temp, oct$temp,\n        names = c(\"July\", \"October\"),\n        ylab = \"Daily maximum temperature (degrees C) in Leeds\"\n)\n\n\n\n\n\n\n\n\n(And yes, I did check the outlier to make sure it was a genuine datapoint.)"
  },
  {
    "objectID": "sections/L02-dataviz.html#histograms",
    "href": "sections/L02-dataviz.html#histograms",
    "title": "2  Data visualisations",
    "section": "2.2 Histograms",
    "text": "2.2 Histograms\n\nOften when collecting data, we don’t collect exact data, but rather collect data clumped into “bins”. For example, suppose a student wished to use a questionnaire to collect data on how long it takes people to reach campus from home; they might not ask “Exactly how long does it take?”, but rather give a choice of tick boxes: “0–5 minutes”, “5–10 minutes”, and so on.\nConsider the following binned data, from \\(n = 100\\) students:\n\n\n\nTime\nFrequency\nRelative frequency\n\n\n\n\n0–5 minutes\n4\n0.04\n\n\n5–10 minutes\n8\n0.08\n\n\n10–15 minutes\n21\n0.21\n\n\n15–30 minutes\n42\n0.42\n\n\n30–45 minutes\n15\n0.15\n\n\n45–60 minutes\n8\n0.08\n\n\n60–120 minutes\n2\n0.02\n\n\nTotal\n100\n1\n\n\n\nHere the frequency \\(f_j\\) of bin \\(j\\) is simply the number of observations in that bin; so, for example, 42 students had journey lengths of between 15 and 30 minutes. The relative frequency of bin \\(j\\) is \\(f_j/n\\); that is, the proportion of the observations in that bin.\nWhich bin would you say is the most popular – that is, the “modal” bin? The bin with the most observations in it is the “15–30 minute” bin. But this bin covers 15 minutes, while some of the other bins only cover 5 minutes. It would be a fairer comparison to look at the frequency density: the relative frequency divided by the size of the bin.\n\n\n\nTime\nFrequency\nRelative frequency\nFrequency density\n\n\n\n\n0–5 minutes\n4\n0.04\n0.008\n\n\n5–10 minutes\n8\n0.08\n0.016\n\n\n10–15 minutes\n21\n0.21\n0.042\n\n\n15–30 minutes\n42\n0.42\n0.028\n\n\n30–45 minutes\n15\n0.15\n0.010\n\n\n45–60 minutes\n8\n0.08\n0.005\n\n\n60–120 minutes\n2\n0.02\n0.0003\n\n\nTotal\n100\n1\n\n\n\n\nIn the first row, for example, the relative frequency is 0.04 and the size of the bin is 5 minutes, so the frequency density is \\(0.04/5 = 0.008\\). We now see that the modal bin – the bin with the highest frequency density – is in fact the “10–15 minutes” bin. This bin has somewhat fewer datapoints that the “15–30 minutes” bin, but they’re squashed into a much smaller bin.\nData in bins can be illustrated with a histogram. A histogram has the measurement on the x-axis, with one bar across the width of each bin, where bars are drawn up to the height of the corresponding frequency density. Note that this means that the area of the bar is exactly the relative frequency of the corresponding bin.\nIf all the bins are the same width, frequency density is directly proportional to frequency and to relative frequency, so it can be clearer use one of those as the y-axis instead in the equal-width-bins case.\nHere is a histogram for our journey-time data:\n\njourneys <- read.csv(\"https://mpaldridge.github.io/math1710/data/journeys.csv\")\nbins <- c(0, 5, 10, 15, 30, 45, 60, 120)\n\nhist(journeys$midpoint, breaks = bins,\n     xlab = \"Journey length (min)\", ylab = \"frequency density\", main = \"\"\n)\n\n\n\n\nOften we draw histograms because the data was collected in bins in the first place. But even when we have exact data, we might choose to divide it into bins for the purposes of drawing a histogram. In this case we have to decide where to put the “breaks” between the bins. Too many breaks too close together, and the small number of observations in each bin will give “noisy” results (see left); too few breaks too far apart, and the wide bins will mean we lose detail (see right).\n\n\n\n\nset.seed(2172)\nhist_data <- c(rnorm(30, 8, 2), rnorm(40, 12, 3))  # Some fake data\n\nhist(hist_data, breaks = 40, main = \"Too many bins\")\nhist(hist_data, breaks = 2,  main = \"Too few bins\")\n\n\n\n\n\n\n\nWe can also calculate some summary statistics even when we have binned data. We mentioned the mode earlier, where the modal bin is the bin of highest frequency density.\nWhat is the median journey length? Well, we don’t know exactly, but \\(0.04 + 0.08 + 0.21\\) (the first three bins) is less than 0.5, while \\(0.04 + 0.08 + 0.21 + 0.42\\) (including the fourth bin) is greater than 0.5. So we know that the median student is in the fourth bin, the “15–30 minute” bin, and we can say that the median journey length is between 15 and 30 minutes.\nSince we don’t have the exact data, it’s not possible to exactly calculate the mean and variance. However, we can often get a good estimate by assuming that each observation was in fact right in the centre of its bin. So, for example, we could assume that all 4 observations in the “0–5 minutes” bin were journeys of exactly 2.5 minutes. Of course, this isn’t true (or is highly unlikely to be true), but we can often get a good approximation this way.\nFor our journey-time data, our approximation of the mean would be [ x = (4 + 8 + + 2) = 24.4 . ] More generally, if \\(m_j\\) is the midpoint of bin \\(j\\) and \\(f_j\\) its frequency, then we can calculate the binned mean and binned variance by \\[\\begin{align*}\n  \\bar x &= \\frac{1}{n} \\sum_j f_j m_j \\\\\n  s^2_x  &= \\frac{1}{n-1} \\sum_j f_j (m_j - \\bar x)^2\n\\end{align*}\\]"
  },
  {
    "objectID": "sections/L02-dataviz.html#scatterplots",
    "href": "sections/L02-dataviz.html#scatterplots",
    "title": "2  Data visualisations",
    "section": "2.3 Scatterplots",
    "text": "2.3 Scatterplots\n\nOften, more than one piece of data is collected from each subject, and we wish to compare that data, to see if there is a relationship between the variables.\nFor example, we could take \\(n\\) second-year maths students, and for each student \\(i\\), collect their mark \\(x_i\\) in MATH1710 and their mark \\(y_i\\) in MATH1712. This gives is two “paired” datasets, \\(\\mathbf x = (x_1, x_2, \\dots, x_n)\\) and \\(\\mathbf y = (y_1, y_2, \\dots, y_n)\\). We can calculate sample statistics of draw plots for \\(\\mathbf x\\) and for \\(\\mathbf y\\) individually. But we might also want to see if there is a relationship between \\(\\mathbf x\\) and \\(\\mathbf y\\): Do students with high marks in MATH1710 also get high marks in MATH1712?\nA good way to visualise the relationship between two variables is to use a scatterplot. In a scatterplot, the \\(i\\)th data pair \\((x_i, y_i)\\) is illustrated with a mark (such as a circle or cross) whose x-coordinate has the value \\(x_i\\) and whose y-coordinate has the value \\(y_i\\).\nIn the following scatterplot, we have \\(n = 50\\) datapoints for the 50 US states; for each state \\(i\\), \\(x_i\\) is the Republican share of the vote in that state in the 2016 Trump–Clinton presidential election, and \\(y_i\\) is the Republican share of the vote in that state in the 2020 Trump–Biden election.\n\nelections <- read.csv(\"https://mpaldridge.github.io/math1710/data/elections.csv\")\n\nplot(elections$X2016, elections$X2020,\n     col = \"blue\",\n     xlab = \"Republican share of the two-party vote, 2016 (%)\",\n     ylab = \"Republican share of the two-party vote, 2020 (%)\")\n\nabline(h = 50, col = \"grey\")\nabline(v = 50, col = \"grey\")\nabline(0.195, 0.963, col = \"red\")\n\n\n\n\nWe see that there is a strong relationship between \\(\\mathbf x\\) and \\(\\mathbf y\\), with high values of \\(x\\) corresponding to high values of \\(y\\) and vice versa. Further, the points on the scatterplot lie very close to a straight line.\nA useful summary statistic here is the correlation [ r_{xy} = , ] where \\(s_{xy}\\) is the sample covariance [ s_{xy} = _{i=1}^n (x_i - x)(y_i - y) , ] and \\(s_x = \\sqrt{s_x^2}\\) and \\(s_y = \\sqrt{s_y^2}\\) are the standard deviations.\nThe correlation \\(r_{xy}\\) is always between \\(-1\\) and \\(+1\\). Values of \\(r_{xy}\\) near \\(+1\\) indicate that the scatterpoints are close to a straight line with an upward slope (big \\(x\\) = big \\(y\\)); values of \\(r_{xy}\\) near \\(-1\\) indicate that the scatterpoints are close to a straight line with a downward slope (big \\(x\\) = small \\(y\\)); and values of \\(r_{xy}\\) near 0 indicate that there is a weak linear relationship between \\(x\\) and \\(y\\).\nFor the elections data, the correlation is\n\ncor(elections$X2016, elections$X2020)\n\n[1] 0.9919659\n\n\nwhich, as we expected, is extremely high."
  },
  {
    "objectID": "sections/L02-dataviz.html#summary-02",
    "href": "sections/L02-dataviz.html#summary-02",
    "title": "2  Data visualisations",
    "section": "Summary",
    "text": "Summary\n\n\nBoxplots show the shape of numerical data, and can compare different datasets.\nHistograms show the shape of binned data.\nScatterplots show the relationship between two datasets."
  },
  {
    "objectID": "about.html#organisation",
    "href": "about.html#organisation",
    "title": "About MATH1710",
    "section": "Organisation of MATH1710",
    "text": "Organisation of MATH1710\nThis module is MATH1710 Probability and Statistics I. (It is possible to take this module as half of MATH2700 Probability and Statistics for Scientists, but I am not aware that any students are enrolled on MATH2700 this year – please let me know if you are.)\nThis module lasts for 11 weeks from 3 October to 16 December 2022. The exam will take place between 16 and 27 January 2023.\nThe module leader, the lecturer, and the main author of these notes is Dr Matthew Aldridge (you can call me “Matt” or “Dr Aldridge”, pronounced “old-ridge”).\n\nLectures\nThe main way you will learn new material for this module is by attending lectures. There are two lectures per week. Because this is a very large class, you are split into two groups for lectures:\n\nGroup 1: Mondays at 1200 and Wednesdays at 1600\nGroup 2: Mondays at 1500 and Wednesdays at 1500\n\nAll lectures are in Roger Stevens LT 20. Check your timetable to see which group you are in.\nI recommend taking your own notes during the lecture. This website will keep brief notes from the lectures, summarising the main definitions and theorems, but will not reflect all the details I say and write during the lectures. Lectures will go through material quite quickly and the material may be quite difficult, so it’s likely you’ll want to spend time reading through your notes after the lecture.\nYou are probably reading the web version of the notes. If you want a PDF copy (to read offline or to print out), it can be downloaded via the top ribbon of the page. (Warning: I have not made as much effort to make the PDF as neat and tidy as I have the web version, and there may be formatting errors.) I am very keen to hear about errors in the notes, mathematical, typographical or otherwise. Please email me if think you may have found any.\nAttendance at lectures is compulsory.\n\n\nProblem sheets\nThere will be 5 problem sheets. Each problem sheet has a number of short and long questions for you to cover in your own time to help you learn the material, and two assessed questions, which you should submit for marking. The assessed questions on each problem sheet make up 3% of your mark on this module, for a total of 15%. Deadlines are 2pm on Mondays, although I’d personally recommend completing and submitting the work in the previous week.\n\n\n\nProblem Sheet\nLectures covered\nDeadline for assessed work\n\n\n\n\n1\n1 and 2\nMonday 17 October (Week 3)\n\n\n2\n3–6\nMonday 31 October (Week 5)\n\n\n3\n7–10\nMonday 14 November (Week 7)\n\n\n4\n11–14\nMonday 28 November (Week 9)\n\n\n5\n15–18\nMonday 12 December (Week 11)\n\n\n\nAn informal Problem Sheet 6 covering material from Lectures 19 and 20 will be available; Lectures 21 and 22 are revision lectures with no new material.\nAssessed questions should be submitted in PDF format through Gradescope. (Further Gradescope details will follow.) Most students choose to hand-write their solutions on paper and then scan them to PDF using their phone; you should use a proper scanning app – we recommend Microsoft Office Lens or Adobe Scan – and not just submit photographs.\n\n\nTutorials\nTutorials are small groups of about a dozen students. You have been assigned to one of 38 tutorial groups, each with a member of staff as the tutor. Your tutorial group will meet five times, in Weeks 2, 4, 6, 8, and 10; you should check your timetable to see when and where your tutorial group meets.\nThe main goal of the tutorials will be to go over your answers to the non-assessed questions on the problems sheets in an interactive session. In this smaller group, you will be able to ask detailed questions of your tutor, and have the chance to discuss your answers to the problem sheet. Your tutor may ask you to present some of your work to your fellow students, or may give you the opportunity to work together with others during the tutorial. Your tutor may be willing to give you a hint on the assessed questions if you’ve made a first attempt but have got stuck. Because of the much smaller groups, the tutorials are the most valuable type of teaching on the module; you should make sure you attend, and you should be well prepared to ensure you make the most of the opportunity.\nMy recommended approach to problem sheets and tutorials is the following:\n\nWork through the problem sheet before the tutorial, spending plenty of time on it, and making multiple efforts at questions you get stuck on. I recommend spending at least 4 hours per problem sheet. This is a long time, but you shouldn’t expect to be able to answer the hardest questions on a problem sheet with making multiple attempts. You don’t have to wait until all lectures in a section are complete until starting to work on some of the questions – this is particularly important for students with Monday tutorials. Collaboration is encouraged when working through the non-assessed problems, but I recommend writing up your work on your own; answers to assessed questions must be solely your own work.\nTake advantage of the small group setting of the tutorial to ask for help or clarification on questions you weren’t able to complete.\nAfter the tutorial, attempt again the questions you were previously stuck on.\nIf you’re still unable to complete a question after this second round of attempts, then consult the solutions.\n\nYour tutor will also be the marker of your answers to the assessed questions on the problem sheets.\nAttendance at tutorials is compulsory.\n\n\nR worksheets\nR is a programming language that is particularly good at working with probability and statistics. Learning to use R is an important part of this module, and is used in many other modules in the University, particularly in MATH1712 Probability and Statistics II. R is used by statisticians throughout academia and increasingly in industry too. Learning to program is a valuable skill for all students, and learning to use R is particularly valuable for students interested in statistics and related topics like actuarial science.\nYou will learn R by working through one R worksheet each week in your own time. Worksheets 3, 5, 7, 9 and 11 will also contain a few questions for assessment, which will be due by 2pm Monday the following week (except the last one). Each of these is worth 3% of your mark for a total of 15%. You will submit your answers through a Microsoft Form (details to follow later). I recommend spending one hour per week on the week’s R worksheet, plus one extra hour if there are assessed questions that week.\n\n\n\n\n\n\n\n\nWeek\nWorksheet\nDeadline for assessed work\n\n\n\n\n1\nR basics\n—\n\n\n2\nVectors\n—\n\n\n3\nData in R\nMonday 24 October (Week 4)\n\n\n4\nPlots I: Making plots\n—\n\n\n5\nPlots II: Making plots better\nMonday 7 November (Week 6)\n\n\n6\nRMarkdown (optional)\n—\n\n\n7\nDiscrete distributions\nMonday 21 November (Week 8)\n\n\n8\nDiscrete random variables\n—\n\n\n9\nNormal distribution\nMonday 5 December (Week 10)\n\n\n10\nLaw of large numbers\n—\n\n\n11\nRecap\nThursday 15 December (Week 11)\n\n\n\nYou can read more about the language R, and about the program RStudio that we recommend you use to interact with R, in the R section of these notes.\nTo help you if you have problems with R, we have organised optional R troubleshooting drop-in sessions, where you can discuss any problems you have with an R expert, in Weeks 2 and 3. Check your timetable for details – these will be listed on your timetable as “practicals”.\nAttendance at R troubleshooting drop-in sessions is optional.\n\n\nOptional “office hours” drop-in sessions\nIf you there is something in the module you wish to discuss privately one-on-one with the module leader, the place for the is the optional weekly “office hours”, which will operate as drop-in sessions. These sessions are an optional opportunity for you to ask questions you have to a member of staff; these are particularly useful if there’s something on the module that you are stuck on or confused about, but I’m happy to discuss any statistics-related issues or questions you have.\nI currently plan two optional “office hours” drop-in session per week:\n\nThursdays from 1400 to 1500 in Roger Stevens LT 7\nThursdays from 1600 to 1700 in Roger Stevens LT 17\n\nAlthough only the second of these appears on your timetable, you are equally welcome at either. Depending on attendance levels, I may change arrangements as term continues. If neither time is possible, you may email me to book a time to talk to me.\nAttendance at “office hours” drop-in sessions is optional. You should prioritise mandatory sessions (like lectures or tutorials, such as for LUBS1940 Economics for Management) over this optional session.\n\n\nTime management\nIt is, of course, up to you how you choose to spend your time on this module. But my recommendations for your work would be something like this:\n\nLectures: 2 hours per week, plus 1 hour per week reading through notes.\nProblem sheets: 4 hours per problem sheet, plus 1 extra hour for writing up and submitting answers to assessed questions.\nR worksheets: 1 hour per week, plus 1 extra hour if there are assessed questions.\nTutorials: 1 hour every other week.\nRevision: 15 hours total at the end of the module.\nExam: 2 hours.\n\nThat makes 100 hours in total. (MATH1710 is a 10-credit module, so is supposed to represent 100 hours work. MATH2700 students are expected to be able to use their greater experience to get through the material in just 75 hours, so should scale these recommendations accordingly.)\n\n\nExam\nThere will be an exam in January, which makes up the remaining 70% of your mark. The exam will consist of 20 short and 2 long questions, and will be time-limited to 2 hours. We’ll talk more about the exam format near the end of the module.\n\n\nWho should I ask about…?\nThere are over 420 students on this module. If each student emails me once a week, and if each email takes me 10 minutes to read and respond, that will take more than 14 hours of my time every day. Generally, it’s much better to come to speak to me at the “office hours” drop-in session or, if it will be very quick, before or after a lecture.\n\nI don’t understand something in the notes or on a problem sheet: Come to office hours, or ask your tutor in your next tutorial.\nI’m having difficulties with R: In Weeks 2 or 3, you should attend an R trouble-shooting drop-in session; at other times, come to office hours.\nI have an admin question about arrangements for the module: Come to office hours or talk to me before/after lectures.\nI have an admin question about arrangements for my tutorial: Contact your tutor.\nI have an admin question about general arrangements for my programme as a whole: Contact the Student Information Service or speak to your personal academic tutor.\nI have a question about the marking of my assessed work on the problem sheets: First, check your feedback on Gradescope; if you still have questions, contact your tutor.\nI have a question about the marking of my assessed work on the R worksheets: You can email me about this.\nDue to truly exceptional and unforeseeable personal circumstances I require an extension on or exemption from assessed work: You can apply by filling in the mitigating circumstances form at this link. Neither I nor your tutor can unilaterally offer an extension or exemption, so please don’t ask. (Only exemptions, not extensions, are available for R worksheets.)"
  },
  {
    "objectID": "about.html#about-content",
    "href": "about.html#about-content",
    "title": "About MATH1710",
    "section": "Content of MATH1710",
    "text": "Content of MATH1710\n\nPrerequisites\nThe formal prerequisite for MATH1710 is “Grade B in A-level Mathematics or equivalent”. I’ll assume you have some basic school-level maths knowledge, but I won’t assume you’ve studied probability or statistics in detail before (although I recognise that many of you will have). If you have studied probability and/or statistics at A-level (or post-16 equivalent) level, you’ll recognise some of the material in this module; however you should find that we go deeper in some areas, and that we treat the material through with a greater deal of mathematical formality and rigour. “Rigour” here means precisely stating our assumptions, and carefully proving how other statements follow from those assumptions.\n\n\nSyllabus\nThe module has three parts: a short first part on “exploratory data analysis”, a long middle part on probability theory, and a short final part on a statistical framework called “Bayesian statistics”. There’s also the weekly R worksheets, which you could count as a fourth part running in parallel, but which will connect with the other parts too.\nAn outline plan of the topics covered is the following.\n\nExploratory data analysis [2 lectures]: Summary statistics, data visualisation\nProbability [16 lectures]:\n\nProbability with events: Probability spaces, probability axioms, examples and properties of probability, “classical probability” of equally likely events, independence, conditional probability, Bayes’ theorem [6 lectures]\nProbability with random variables: Discrete random variables, expectation and variance, binomial distribution, geometric distribution, Poisson distribution, multiple random variables, law of large numbers, continuous random variables, exponential distribution, normal distribution, central limit theorem [10 lectures]\n\nBayesian statistics [2 lectures]: Bayesian framework, Beta prior, normal–normal model\nSummary and revision [2 lectures]\n\nYou’ll notice that this module is heavier on the “Probability” than the “Statistics” of its title. MATH1712 Probability and Statistics II, on the other hand, which many students on this module will take next semester, is almost entirely “Statistics”.\n\n\nBooks\nYou can do well on this module by reading the notes and watching the videos, attending the lectures and tutorials, and working on the problem sheets and R worksheets, without needing to do any further reading beyond this. However, students can benefit from optional extra background reading or an alternative view on the material, especially in the parts of the module on probability. These books are also a good place to look if you want extra exercises and problems for revision.\nFor exploratory data analysis, you can stick to Wikipedia, but if you really want a book, I’d recommend:\n\nGM Clarke and D Cooke, A Basic Course in Statistics, 5th edition, Edward Arnold, 2004.\n\nFor the probability section, any book with a title like “Introduction to Probability” would do. Some of my favourites are:\n\nJK Blitzstein and J Hwang, Introduction to Probability, 2nd edition, CRC Press, 2019.\nG Grimmett and D Welsh, Probability: An Introduction, 2nd edition, Oxford University Press, 2014. (The library has online access.)\nSM Ross, A First Course in Probability, 10th edition, Pearson, 2020.\nRL Scheaffer and LJ Young, Introduction to Probability and Its Applications, 3rd edition, Cengage, 2010.\nD Stirzaker, Elementary Probability, 2nd edition, Cambridge University Press, 2003. (The library has online access.)\n\nI also found lecture notes by Prof Oliver Johnson (University of Bristol) and Prof Richard Weber (University of Cambridge) to be useful.\nOn Bayesian statistics, we will only taste a brief introduction, but if you want a book, I recommend:\n\nJV Stone, Bayes’ Rule: A Tutorial Introduction to Bayesian Analysis, Sebtel Press, 2013.\n\nFor R, there are many excellent resources online.\n(For all these books I’ve listed the newest editions, but older editions are usually fine too.)"
  },
  {
    "objectID": "about.html#about-notes",
    "href": "about.html#about-notes",
    "title": "About MATH1710",
    "section": "About these notes",
    "text": "About these notes\nThese notes were written by Matthew Aldridge in 2021, and were edited and updated in 2022. They are based in part on previous notes by Dr Robert G Aykroyd and Prof Wally Gilks. Dr Jason Susanna Anquandah and Dr Aykroyd advised on the R worksheets. Dr Aykroyd’s help and advice on many aspects of the module was particularly valuable.\nThese notes (in the web format) should be accessible by screenreaders. If you have accessibility difficulties with these notes, contact me."
  },
  {
    "objectID": "sections/L05-classical-i.html#classical-intro",
    "href": "sections/L05-classical-i.html#classical-intro",
    "title": "5  Classical probability I",
    "section": "5.1 Probability with equally likely outcomes",
    "text": "5.1 Probability with equally likely outcomes\n\nClassical probability is the name we give to probability where there are a finite number of equally likely outcomes.\nClassical probability was the first type of probability to be formally studied – partly because it is the simplest, and partly because it was useful for working out how to win at gambling. Tossing fair coins, rolling dice, and dealing cards are all common gambling situations that can be studied using classical probability – in a deck of cards, for example, there are 52 cards that are equally likely to be drawn. Among the first works to seriously study classical probability were “Book on Games of Chance” by Girolamo Cardano (written in 1564, but not published until 1663, one hundred years later), and a famous series of letters letters between Blaise Pascal and Pierre de Fermat in 1654.\n\nLet \\(\\Omega\\) be a finite sample space. Then the classical probability measure on \\(\\Omega\\) is given by [ P(A) = . ]\n\nSo to work out a classical probability \\(\\mathbb P(A)\\), crucially we need to be able to count how many outcomes \\(|A|\\) are in the event \\(A\\) and count how many outcomes \\(|\\Omega|\\) are in the whole sample space \\(\\Omega\\). (This is why classical probability is also called “enumerative probability” – “enumeration” is another word for counting.) In this lecture and the next, we’ll look at some different ways in which we can count the number of outcomes in common events and sample spaces.\n\nWe roll a dice. What is the probability we get at least 5?\nThe sample space is \\(\\Omega = \\{1,2,3,4,5,6\\}\\), with \\(|\\Omega| = 6\\). The event that we roll at least 5 is \\(A = \\{5,6\\}\\), with \\(|A| = 2\\). Hence [ P(A) = = = . ]\n\nThere’s something we ought to check before going any further!\n\nLet \\(\\Omega\\) be a finite nonempty sample space. Then the classical probability measure on \\(\\Omega\\), [ P(A) = , ] is indeed a probability measure, in that it satisfies the three axioms in Definition @ref(def:axioms).\n\n\nProof. We’ll take the axioms one by one.\n\nSince \\(|\\Omega| \\geq 1\\) and \\(|A| \\geq 0\\), it is indeed the case that \\(\\mathbb P(A) = |A|/|\\Omega| \\geq 0\\).\nWe have \\({\\displaystyle \\mathbb P(\\Omega) = \\frac{|\\Omega|}{|\\Omega|} = 1}\\), as required.\nSince we have a finite sample space, we only need to show Axiom 3 for a sequence of two disjoint events; the argument can be repeated to get any finite number of events. Let \\(A = \\{a_1, a_2, \\dots, a_k\\}\\) and \\(B = \\{b_1, b_2, \\dots, b_l\\}\\) be two disjoint events with \\(|A| = k\\) and \\(|B| = l\\). Note that we can enumerate the elements of the disjoint union \\(C = A \\cup B\\) as [ c_1 = a_1, c_2 = a_2, , c_k = a_k, c_{k+1} = b_1, c_{k+2} = b_2, , c_{k+l} = b_l . ] Since \\(A\\) and \\(B\\) are disjoint, this list has no repeats, and we see that \\(|C| = |A \\cup B| = k+l\\). Hence [ P(A B) = = + = P(A) + P(B) , ] and Axiom 3 is fulfilled."
  },
  {
    "objectID": "sections/L05-classical-i.html#multiplication",
    "href": "sections/L05-classical-i.html#multiplication",
    "title": "5  Classical probability I",
    "section": "5.2 Multiplication principle",
    "text": "5.2 Multiplication principle\n\nIn classical probability, to find the probability of an event \\(A\\), we need to count the number of outcomes in \\(A\\) and the total number of possible outcomes in \\(\\Omega\\). This can be easy when we’re just looking at one choice – like the 2 outcomes from tossing a single coin, the 6 outcomes of rolling a single dice, or the 52 outcomes from dealing a single card. Now we’re going to look at what happens if there are a number of choices one after another – like tossing multiple coins, rolling more than one dice, or dealing a hand of cards.\nHere, an important principle is the multiplication principle. The multiplication principle says that if you have \\(n\\) choices followed by \\(m\\) choices, than all together you have \\(n \\times m\\) total choices. You can see this by imagining the choices in a \\(n \\times m\\) grid, with the \\(n\\) columns representing the first choice and \\(m\\) rows representing the second choice. For example, suppose you go to a burger restaurant where there are 3 choices of burger (beefburger, chicken burger, veggie burger) and 2 choices of sides (fries, salad), then altogether there are \\(3 \\times 2 = 6\\) choices of meal.\n\n\n\n\n\n\n\n\n\n\nBeefburger\nChicken burger\nVeggie burger\n\n\n\n\nFries\n1: Beefburger with fries\n2: Chicken burger with fries\n3: Veggie burger with fries\n\n\nSalad\n4: Beefburger with salad\n5: Chicken burger with salad\n6: Veggie burger with salad\n\n\n\nMore generally, if you have \\(m\\) stages of choosing, with \\(n_1\\) choices in the first stage, then \\(n_2\\) choices in the second stage, all the way to \\(n_m\\) choices in the final stage, you have \\(n_1 \\times n_2 \\times \\cdots \\times n_m\\) total choices altogether.\n\n\nFive fair coins are tossed. What is the probability they all show the same face?\nHere, the sample space \\(\\Omega\\) is the set of all sequences of 5 coin outcomes. How many sample outcomes are in \\(\\Omega\\)? Well, the first coin can be heads or tails (2 choices); the second coin can be heads or tails (2 choices) and so on, until the fifth and final coin. So, by the multiplication principle, \\(|\\Omega| = 2 \\times 2 \\times 2 \\times 2 \\times 2 = 2^5 = 32\\).\nThe event we’re interested in is \\(A = \\{\\text{HHHHH}, \\text{TTTTT}\\}\\), the event that the faces are all the same – either all heads or all tails. This clearly has \\(|A| = 2\\) outcomes.\nSo the probability all five coins show the same face is [ P(A) = = = . ]\n\n\nFour dice are rolled. What is the probability we get at least one 6?\nHere, \\(\\Omega\\) is the set of all possible sequences of four dice rolls. Clearly \\(|\\Omega| = 6^4 = 1296\\).\nThe event \\(A\\) is the set of all dice roll sequences with at least one 6. Whenever you see a question with the phrase “at least one” in it, it’s very often to look at the complementary event \\(A^\\comp\\) instead. We know from the last section that \\(\\mathbb P(A) = 1 - \\mathbb P(A^\\comp)\\), but in “at least one” questions, it’s often easier to count \\(|A^\\comp|\\) than to count \\(|A|\\).\nHere, since \\(A\\) is the set of all dice roll sequences with at least one 6, then \\(A^\\comp\\) is the set of dice roll sequence without any 6s at all. This means all four dice must have rolled a 1, 2, 3, 4 or 5. Since each of the four dice rolls has five possibilities, this means that \\(|A^\\comp| = 5^4 = 625\\).\nPutting this together, we see that [ P(A) = 1 - P(A^) = 1 - = 1 - = .] So there’s about a 52% chance we get at least one 6."
  },
  {
    "objectID": "sections/L05-classical-i.html#sampling",
    "href": "sections/L05-classical-i.html#sampling",
    "title": "5  Classical probability I",
    "section": "5.3 Sampling with and without replacement",
    "text": "5.3 Sampling with and without replacement\n\n\nA bag contains 15 balls: 10 black balls and 5 white balls. We draw 3 balls out of the bag. What is the probability all 3 balls are black (a) if we put each ball back into the bag after it is chosen; (b) if we do not put each ball back into the bag after it is chosen.\nLet’s start with (a). The number of ways to choose a ball out 15 on three occasions is \\(|\\Omega| = 15^3\\). The number of ways to choose a black ball out of 10 on three occasions is \\(|A| = 10^3\\). Hence [ P(A) = = = = . ]\nWhat about (b)? Here we don’t put the ball back in the bag once it has been chosen. There are 15 ways to pick the first ball. But then there are only 14 balls left in the bag for the second choice, and only 13 balls for the third choice. So \\(|\\Omega| = 15\\times14\\times13\\). Similarly, there are 10 ways the first ball can be black. But once that black ball is removed, only 9 choices for the second black ball, and only 8 for the third. So \\(|A| = 10\\times9\\times8\\). So this time we have [ P(A) = = = = , ] which is smaller than the answer in part (a).\n\nThis example illustrated the difference between sampling with replacement (when the balls were put back into the bag) and sampling without replacement (when the balls were not put back). If we want to sample \\(k\\) items from a set of \\(n\\) items, then:\n\nthe number of ways to sample with replacement is [ n^k = nnn; ]\nthe number of ways to sample without replacement is [ = n(n-1)(n-k+1) .]\n\nHere, we’ve defined the notation \\(\\ff{n}{k}\\) for the number of ways to sample without replacement; this is called the falling factorial or permutation number. This is still \\(k\\) numbers multiplied together, but decreasing by 1 each time down from \\(n\\). The final number in the product is the number of choices in the \\(k\\)th an final round: this is the original \\(n\\) items minus the \\(k-1\\) items sampled in the previous \\(k-1\\) rounds; so the final number is \\(n - (k-1) = n - k + 1\\), not \\(n - k\\). A notation point: Notice that the subscript is underlined in the falling factorial; other notation sometimes used includes \\((n)_k\\), \\(P(n,k)\\), or \\({}^nP_k\\)."
  },
  {
    "objectID": "sections/L05-classical-i.html#summary-L05",
    "href": "sections/L05-classical-i.html#summary-L05",
    "title": "5  Classical probability I",
    "section": "Summary",
    "text": "Summary\n\n\n“Classical probability” describes the situation where there are finitely many equally likely outcomes. The classical probability \\(\\mathbb P(A) = |A|/|\\Omega|\\) requires us to count how many outcomes there are in events or sample spaces.\nThe multiplication principle says that \\(n\\) choices followed by \\(m\\) choices makes \\(n \\times m\\) choices in total.\nSampling \\(k\\) objects out of \\(n\\) with replacement gives \\(n^k\\) choices.\nSampling \\(k\\) objects out of \\(n\\) without replacement gives \\(n^{\\underline{k}} = n(n-1)\\cdots(n-k+1)\\) choices."
  },
  {
    "objectID": "sections/L06-classical-ii.html#ordering",
    "href": "sections/L06-classical-ii.html#ordering",
    "title": "6  Classical probability II",
    "section": "6.1 Ordering",
    "text": "6.1 Ordering\n\n\nSuppose a lecturer marks a pile of \\(n\\) exam papers, all of which receive a different mark. What is the probability she ends up marking them in order from lowest scoring first in the pile to highest scoring last in the pile?\nHere, the sample space \\(\\Omega\\) is the set of all orderings of the \\(n\\) exam papers by mark, and \\(A\\) is the event that the papers are in order from lowest to highest scoring. It’s clear that \\(|A| = 1\\): since the exams scored different marks, there’s only one way of putting the exams in the correct lowest-to-highest order. But what’s \\(|\\Omega|\\)?\nThere are \\(n\\) choices for the first exam paper to be marked. Then, for the second exam paper, there are \\(n - 1\\) choices left, because the lecturer is not going to mark the same paper twice. There are \\(n-2\\) choices for the third exam paper. And so on, until she has marked \\(n-1\\) papers, and there is only 1 choice left for the final paper. So we have [ || = nn = n(n-1)(n-2) = n! ] ways to order the exam papers.\nHence, the probability the papers are marked in order is [ P(A) = = = . ]\n\nThis number [ n! = nn = n(n-1)(n-2) ] is called \\(n\\) factorial and denoted \\(n!\\). It is the number of ways that \\(n\\) different objects can be ordered.\nThe factorial \\(n!\\) gets very large very quickly. Stirling’s formula gives the approximation \\(n! \\approx \\sqrt{2\\pi n} \\, \\mathrm{e}^{-n} \\, n^n\\).\n\nSuppose you shuffle a pack of cards. The resulting ordering of the deck has \\(52!\\) possibilities. This is an unimaginably huge number – the exact value to 3 significant figures is [ 52! = 8.07 ^{67} , ] while Stirling’s formula gives the approximation [ 52! ^{-52} ^{52} = 8.05 ^{67} . ] This is an 8 followed by 67 zeroes.\nIf every person on the planet (very roughly \\(10^{10}\\)) had shuffled a deck of cards one million (\\(10^6\\)) times a second for the entire lifetime of the universe (roughly \\(10^{17}\\) seconds), they could only expect to have got through about \\(10^{33}\\) shuffles. This is only the most tiny, microscopic fraction of \\(52!\\). So every time you have ever shuffled a deck of cards, it is essentially certain that you have created an ordering of the deck that has never existed before.\n\nIf we take the ratio of a bigger factorial \\(n!\\) over a smaller factorial \\(j!\\), we get lot of cancellation, \\[\\begin{align*}\n\\frac{n!}{j!} &= \\frac{n(n-1) \\cdots(j+1)j(j-1) \\cdots 1}{j(j-1) \\cdots 1} \\\\\n  &= n(n-1) \\cdots (j+1) ,\n\\end{align*}\\] because the last part of the product in the numerator cancels with the whole of the denominator. Replacing \\(j\\) with \\(n-k\\), this gives [ = n(n-1) (n - k + 1) = . ] This gives a way of writing the falling factorial as the ratio of two (normal) factorials, which can sometimes be useful."
  },
  {
    "objectID": "sections/L06-classical-ii.html#combinations",
    "href": "sections/L06-classical-ii.html#combinations",
    "title": "6  Classical probability II",
    "section": "6.2 Sampling without replacement in any order",
    "text": "6.2 Sampling without replacement in any order\n\n\nIn the Lotto, the UK national lottery, you can buy a ticket for £2 and choose 6 numbers between 1 and 59. If your 6 numbers match the 6 numbers on the balls chosen by the lottery machine, you win the jackpot (usually between £2 million and £20 million, shared between the tickets that get all 6 numbers). If you buy a ticket, what is the probability you win the jackpot?\nHere, \\(\\Omega\\) is the set of all possible sets of 6 winning numbers, and \\(A\\) is the set of numbers on your ticket. Clearly \\(|A| = 1\\), but what is \\(|\\Omega|\\)?\nWell, the first ball out of the machine has 59 possibilities, the second ball has 58 possibilities, and so on, making [ 59 = . ]\nBut this isn’t the correct answer, because the same set of balls could be drawn from the machine in any order! The sets of balls \\(\\{1,2,3,4,5,6\\}\\) and \\(\\{1,2,3,4,6,5\\}\\) and \\(\\{6,5,4,3,2,1\\}\\) are all the same set of numbers. How many ways can we see the same list of numbers? This is precisely the number of orderings of 6 balls, which we know is \\(6!\\). So the number of possible sets of 6 balls to come out of the machine is actually [ = = . ]\nThus the probability that your ticket wins the jackpot is [ P(A) = = ,000,02 . ]\n\nHere, we have introduced the notation [ = = ] for the number of ways to choose \\(k\\) objects out of \\(n\\) without replacement and where the order they were chosen in doesn’t matter. This is called the binomial coefficient, although when we say it out loud we normally just say “\\(n\\) choose \\(k\\)”. (Another notation for the binomial coefficient is \\({}^n C_k\\).)\nIt can sometimes be useful to remember that \\(\\ff nk = n!/(n-k)!\\) allows us to write the binomial coefficient in terms of the factorial function as [ nk = = . ]\n\nYou are dealt a “hand” of 13 cards from a deck of 52 cards. What is the probability that you have the Ace, King, Queen, and Jack of Spades?\nHere, \\(\\Omega\\) is the set of all 13-card hands from the deck, and \\(A\\) is the subset of those that contain the AKQJ of Spades.\nUsing the binomial coefficient notation, it’s clear that [ || = = . ]\nWhat about \\(|A|\\)? If we fix the fact that the hand contains the 4 cards AKQJ of Spades, then it also contains \\(13-4=9\\) cards out of the other \\(52-4 = 48\\) remaining cards in the deck. This makes [ |A| = = ] hands.\nThus the probability that the hand contains AKQJ of Spades is [ P(A) = = . ]\nConveniently, we can simplify the expression quite a lot, because plenty of cancellation will occur. We have \\[\\begin{align*}\n\\mathbb P(A) = \\frac{\\binom{48}{9}}{\\binom{52}{13}}\n  &= \\frac{\\frac{48\\times47\\times\\cdots\\times41\\times40}{9\\times8\\times\\cdots\\times2\\times1}}{\\frac{52\\times51\\times\\cdots\\times41\\times40}{13\\times12\\times\\cdots\\times2\\times1}} \\\\\n  &= \\frac{48\\times47\\times\\cdots\\times41\\times40}{52\\times51\\times\\cdots\\times41\\times40} \\times \\frac{13\\times12\\times\\cdots\\times2\\times1}{9\\times8\\times\\cdots\\times2\\times1} \\\\\n  &= \\frac{13\\times12\\times11\\times10}{52\\times51\\times50\\times49} \\\\\n  &\\approx 0.0026 ,\n\\end{align*}\\] or about 1 in every 380 hands."
  },
  {
    "objectID": "sections/L06-classical-ii.html#birthday",
    "href": "sections/L06-classical-ii.html#birthday",
    "title": "6  Classical probability II",
    "section": "6.3 Birthday problem",
    "text": "6.3 Birthday problem\n\n\nThere are \\(k = 23\\) students in a class. What is the probability that at least two of the students share a birthday?\nThis a famous problem, known as the “birthday problem”. You may have seen this problem before – but let’s try to solve it using the techniques from this section of notes. If you haven’t seen it before, you might like to guess what you think the answer might be. (We’ll assume all days are equally likely for birthdays, and ignore the leap day 29 February.)\nThe sample space \\(\\Omega\\) is the set of possible birthdays for the \\(k\\) students. Clearly \\(|\\Omega| = 365^k\\).\nLet \\(A\\) be the even that at least two students share a birthday. Since this is an “at least” event, it seems like it might be a good idea to look instead at the complementary event \\(A^\\comp\\). If \\(A\\) is the event that there’s at least one shared birthday, then \\(A^\\comp\\) is the event that there are no shared birthdays; that is, \\(A^\\comp\\) is the event that all \\(k\\) students have different birthdays.\nSo what is \\(|A^\\comp|\\), the number of ways the \\(k\\) students can have different birthdays? Well, the first student can have any of the 365 days for their birthday. For them to have different birthdays, the second student only has 364 days available. Then the third student must avoid the birthday of students 1 and 2, so has 363 available days, and so on. We see that [ |A^| = 365 (365 - k + 1) = 365^{} . ]\nHence, the probability at least two students share a birthday is [ P(A) = 1 - P(A^) = 1 - = 1 - . ]\nSetting \\(k = 23\\), we can calculate the required answer in R:\n\nk <- 23\n1 - prod((365:(365 - k + 1)) / 365)\n\n[1] 0.5072972\n\n\nThe probability is 50.7%. So it’s more likely than not that at least two students share a birthday.\n\nSome people find it surprising that only 23 students have such a high probability of sharing a birthday, since 23 is so small compared to 365. But remember there are \\(\\binom{23}{2} = 253\\) pairs of birthdays, and each of those 253 pairs is a potential match."
  },
  {
    "objectID": "sections/L06-classical-ii.html#summary-L06",
    "href": "sections/L06-classical-ii.html#summary-L06",
    "title": "6  Classical probability II",
    "section": "Summary",
    "text": "Summary\n\n\nOrdering \\(n\\) objects can be done in \\(n! = n^{\\underline{n}} = n(n-1)\\cdots2\\cdot1\\) ways.\nThe number of ways to sample \\(k\\) objects out of \\(n\\) when the order doesn’t matter is given by the binomial coefficient \\(\\binom nk = \\ff{n}{k}/k!\\)."
  },
  {
    "objectID": "sections/L12-poisson.html#poisson",
    "href": "sections/L12-poisson.html#poisson",
    "title": "12  Poisson distribution",
    "section": "12.1 Definition and properties",
    "text": "12.1 Definition and properties\n\nAnother important distribution is the Poisson distribution. The Poisson distribution (roughly “pwa-song”) is typically used to model “the number of times something happens in a set period of time”. For example, the number of emails you receive in a day; the number of claims at an insurance company each year; or the number of calls to call centre in one hour. (Famously, one of the first historical datasets modelled using a Poisson distribution was “the number of Prussian soldiers in different cavalry units kicked to death by their own horse between 1875 and 1894”.) We’ll explain why the Poisson distribution is a good model for this in the next subsection.\n\nLet \\(X\\) be a discrete random variable with range \\(\\{0,1,2,\\dots\\}\\) and PMF [ p_X(x) = e^{-} . ] Then we say that \\(X\\) follows the Poisson distribution with rate \\(\\lambda\\), and write \\(X \\sim \\text{Po}(\\lambda)\\).\n\nHere, \\(\\lambda\\) is a lower-case Greek letter “lambda”. I should also note that we interpret \\(0! = 1\\), so [ p(0) = e^{-} = e^{-} = e^{-} . ]\n\n\n\n\n\nThe Poisson distribution is named after the French mathematician Siméon-Denis Poisson who wrote about it in 1837, although the origin of the idea is more than 100 years earlier with another French mathematician, Abraham de Moivre.\n\n\nI receive emails from students at the rate of \\(\\lambda = 3\\) per hour, modelled as a Poisson distribution. What is the probability I get (a) two email in an hour, (b) no email in an hour?\nThe number of emails per hour is \\(X \\sim \\mathrm{Po}(3)\\).\nFor (a), we have [ P(X = 3) = p(3) = ^{-3} = ^{-3} = 0.224 . ]\nFor part (b), and remembering that \\(0! = 1\\), we have [ P(X = 3) = p(0) = ^{-3} = ^{-3} = 0.050 . ]\n\nThe parameter \\(\\lambda\\) is called the “rate” because that indeed the number of emails (or insurance claims, or phone calls, or deaths by horse-kicking) that we expect to see.\n\nLet \\(X \\sim \\text{Po}(\\lambda)\\). Then\n\n\\(p(x)\\) is indeed a PMF, in that \\(\\displaystyle\\sum_{x=0}^\\infty p(x) = 1\\).\n\\(\\mathbb EX = \\lambda\\),\n\\(\\Var(X) = \\lambda\\).\n\n\n\nProof. We’ll do the first two here, then you can do the variance in Problem Sheet 4.\nIt will be useful to remember the Taylor series for the exponential function, [ e^= _{x=0}^ . ]\nFor part 1, to see that the PMF does indeed sum to one, note that the Taylor series gives us [ {x=0}^p(x) = {x=0}e{-} = e^{-} _{x=0}^ = e{-},e{} = 1. ]\nFor part 2, for the expectation, we have \\[\\begin{align*}\n\\mathbb EX &= \\sum_{x=0}^\\infty x\\,\\mathrm e^{-\\lambda}  \\frac{\\lambda^x}{x!} \\\\\n  &= \\mathrm e^{-\\lambda} \\sum_{x=1}^\\infty x\\,\\frac{\\lambda^x}{x!} \\\\\n  &= \\mathrm e^{-\\lambda} \\sum_{x=1}^\\infty \\frac{\\lambda^x}{(x-1)!} \\\\\n  &= \\lambda \\mathrm e^{-\\lambda} \\sum_{x=1}^\\infty \\frac{\\lambda^{x-1}}{(x-1)!}\n\\end{align*}\\] In the second line, we took \\(\\mathrm e^{-\\lambda}\\) outside the sum, and allowed ourselves to start the sum from 1, since the \\(x = 0\\) term was 0 anyway; in the third line, we cancelled the \\(x\\) from the \\(x!\\) to get \\((x-1)!\\); and in the fourth line we took one of the \\(\\lambda\\)s in \\(\\lambda^x\\) outside the sum, to give ourselves terms in \\(x - 1\\) inside the sum. We can now “re-index” the sum by putting \\(y = x - 1\\), to get [ EX = e^{-} _{y=0}^ = e^{-} e^{} = , ] where we used the Taylor series again.\n\n\nAt this point in the lecture, we took a break to fill in the mid-semester check-in survey. This is open for the rest of the week and is anonymous. Written comments in answer to the last question are particular useful – I will read them all and report back next week on changes I am making to the module in response to your comments."
  },
  {
    "objectID": "sections/L12-poisson.html#poisson-approx",
    "href": "sections/L12-poisson.html#poisson-approx",
    "title": "12  Poisson distribution",
    "section": "12.2 Poisson approximation to the binomial",
    "text": "12.2 Poisson approximation to the binomial\n\nSuppose I own a watch shop in Leeds. My watches are very expensive, so I don’t need to sell many each day – in fact, I sell an average of 4.8 watches per day. How should I model the number of watches sold each day as a random variable?\nOne way could be to say this. There are \\(n\\) people living in Leeds or nearby, and, on any given day, each of them will independently buy a watch from my shop with some probability \\(p\\). Thus the total number of watches I sell could be modelled as a binomial distribution \\(\\text{Bin}(n, p)\\).\nBut what should \\(n\\) and \\(p\\) be? To make the average \\(\\mathbb EX = np = 4.8\\), I must take \\(p = 4.8/n\\). But what about \\(n\\)? We know \\(n\\) is a very big number, because Leeds is a big city, so let’s take a limit as \\(n \\to \\infty\\). It turns out, that this distribution \\(\\text{Bin}(n, 4.8/n)\\) becomes a Poisson(4.8) distribution!\n\nFix \\(\\lambda \\geq 0\\), and let \\(X_n \\sim \\text{Bin}(n, \\lambda/n)\\) for all integers \\(n \\geq \\lambda\\). Then \\(X_n \\to \\text{Po}(\\lambda)\\) in distribution as \\(n \\to \\infty\\), by which we mean that if \\(Y \\sim \\text{Po}(\\lambda)\\), then [ p_{X_n}(x) p_Y(x) . ]\n\nA looser way to state the principle of this theorem would be this: When \\(n\\) is very large and \\(p\\) very small, in such a way that \\(np\\) is a small-ish number, then \\(\\text{Bin}(n,p)\\) is well approximated by \\(\\text{Po}(\\lambda)\\) where \\(\\lambda = np\\).\nThis is why a Poisson distribution is a good model for the number of occurrences in a set time period. It applies if there lots of things that could happen (large \\(n\\)), each one is individually unlikely (small \\(p\\)), and on average a few of them will actually happen (\\(\\lambda = np\\) small-ish).\n\nA lecturer teaches a module with \\(n = 100\\) students, and estimates that each student turns up to office hours drop-in sessions independently with probability \\(p = 0.035\\). What is the probability that (a) exactly 5, (b) 2 or more students turn up to a drop-in session?\nIf we let \\(X\\) be the number of students that turn up to a drop-in session, then the exact distribution of \\(X\\) is \\(X \\sim \\text{Bin}(100, 0.035)\\).\nFor part (a), we then have [ P(X = 5) = 0.035^5 (1 - 0.035)^{100-5} = 0.134 . ]\nFor part (b), we have an “at least” event, so we use the complement rule to get \\[\\begin{align*}\n\\mathbb P(X \\geq 2)\n&= 1 - \\mathbb P(X = 0) - \\mathbb P(X = 1) \\\\\n&= 1 - \\binom{100}{0} 0.035^0 (1 - 0.035)^{100-0} + \\binom{100}{1} 0.035^1 (1 - 0.035)^{100 - 1} \\\\\n&= 1 - (1 - 0.035)^{100} + 100 \\times 0.035 (1 - 0.035)^{99} \\\\\n&= 1 - 0.028 - 0.103 \\\\\n&= 0.869\n\\end{align*}\\]\nAlternatively, it might be more convenient to approximate \\(X\\) by a Poisson distribution \\(Y \\sim \\text{Po}(100 \\times 0.035) = \\text{Po}(3.5)\\).\nFor part (a), this gives [ P(Y = 5) = e^{-3.5} = 0.132 , ] which is very close to the exact answer above of \\(0.134\\).\nFor part (b), the approximation gives \\[\\begin{align*}\n\\mathbb P(Y \\geq 2)\n&= 1 - \\mathbb P(Y = 0) - \\mathbb P(Y = 1) \\\\\n&= 1 - \\mathrm e^{-3.5} \\frac{3.5^0}{0!} - \\mathrm e^{-3.5} \\frac{3.5^1}{1!} \\\\\n&= 1 - \\mathrm e^{-3.5} - 3.5 \\mathrm e^{-3.5} \\\\\n&= 1 - 0.030 - 0.106 \\\\\n&= 0.864\n\\end{align*}\\] which is very close to the exact answer above of \\(0.869\\).\nThe following graph shows how close the \\(\\text{Po}(3.5)\\) distribution is to a \\(\\text{Bin}(100, 0.035)\\) distribution – not exact, but pretty good.\n\n\n\n\n\n\nFor completeness, we include a proof of Theorem @ref(thm:po-bint) here, although since it discusses use of limits, it’s not examinable material for this module.\n\nProof. (Non-examinable) We need to show that, as \\(n \\to \\infty\\), [ p_X(x) = nx ()^x (1 - )^{n-x} ^{-} = p_Y(x) . ] Let’s try. The left-hand side is, by some simple rearrangements, \\[\\begin{align*}\n\\binom nx &\\left(\\frac{\\lambda}{n}\\right)^x \\left(1 - \\frac{\\lambda}{n}\\right)^{n-x} \\\\\n  &= \\frac{n(n-1)\\cdots(n-x+1)}{x!} \\frac{\\lambda^x}{n^x} \\left(1 - \\frac{\\lambda}{n}\\right)^{n}\\left(1 - \\frac{\\lambda}{n}\\right)^{-x} \\\\\n  &= \\frac{\\lambda^x}{x!} \\frac{n(n-1)\\cdots(n-x+1)}{n^x} \\left(1 - \\frac{\\lambda}{n}\\right)^{n}\\left(1 - \\frac{\\lambda}{n}\\right)^{-x} \\\\\n  &= \\frac{\\lambda^x}{x!} \\frac{n}{n} \\frac{n-1}{n} \\cdots \\frac{n-x+1}{n} \\left(1 - \\frac{\\lambda}{n}\\right)^{n}\\left(1 - \\frac{\\lambda}{n}\\right)^{-x} \\\\\n  &= \\frac{\\lambda^x}{x!} 1 \\left(1 - \\frac{1}{n}\\right) \\cdots \\left(1 - \\frac{x-1}{n}\\right)  \\left(1 - \\frac{\\lambda}{n}\\right)^{n}\\left(1 - \\frac{\\lambda}{n}\\right)^{-x} .\n\\end{align*}\\]\nNow let’s take each of the terms in turn. First \\(\\lambda^x / x!\\) looks very promising, and can stay. Second, each of the terms \\(1, 1 - 1/n, \\dots, 1 - (x-1)/n\\) tend to 1 as \\(n \\to \\infty\\). Third, [ (1 - )^{n} ^{-} ; ] this is from the standard “compound interest” result that [ (1 + )^{n} ^{a} . ] Finally [(1 - )^{-x} , ] as \\(1 - \\lambda/n \\to 1\\), and \\(x\\) is fixed. Putting all that together gives the result."
  },
  {
    "objectID": "sections/L12-poisson.html#poisson-process",
    "href": "sections/L12-poisson.html#poisson-process",
    "title": "12  Poisson distribution",
    "section": "12.3 Poisson process",
    "text": "12.3 Poisson process\nSuppose an insurance company’s call centre is open 10 hours a day, 5 days a week. The call centre receives a “large claim” – a claim in excess of £100,000 – on average 0.2 times per hour. It seems reasonable, therefore, to model the number of large claims in an hour as a \\(\\mathrm{Po}(\\lambda)\\) distribution with \\(\\lambda = 0.2\\).\nHow should we model the nuber of large claims in a day? If the call centre receives \\(\\lambda = 0.2\\) claims per hour, on average, then it receives \\(10\\lambda = 2\\) claims per 10 hours, or one day. It seems reasonable to model this with a \\(\\mathrm{Po}(10\\lambda)\\) distribution.\nFurther, the number of claims on one day and on the next day seems like they should be independent.\nThe two ideas in the model above lead to what is called the “Poisson process”.\n\nA random set of arrivals is said to follow a Poisson process with rate \\(\\lambda\\) if\n\nThe number of arrivals in a time period of length \\(t\\) is \\(\\mathrm{Po}(\\lambda t)\\).\nThe number of arrivals in two non-overlapping time periods are independent.\n\n\n\nSuppose the number of large claims, as discussed above, is modelled as a Poisson process with rate \\(\\lambda = 0.2\\) claims per hour. What is the probability the call centre receives at least one large claim every day this week?\nThe number of large claims in one 10-hour day is \\(X \\sim \\mathrm{Po}(10\\lambda) = \\mathrm{Po}(2)\\). So the probability of getting at least one claim in a day is [ P(X ) = 1 - P(X = 0) = 1 - ^{-2} = 0.865 . ]\nBecause the number of claims in each of the five days this week are independent, the probability of getting at least one claim in all five days is [ P(X )^5 = 0.865^5 = 0.483 . ]\n\nThis is just a brief taster of the Poisson process. The Poisson process is studied in much more detail in the second-year module MATH2750 Introduction to Markov Processes."
  },
  {
    "objectID": "sections/L12-poisson.html#summary-06",
    "href": "sections/L12-poisson.html#summary-06",
    "title": "12  Poisson distribution",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\n\n\nDistribution\nRange\nPMF\nExpectation\nVariance\n\n\n\n\nBernoulli: \\(\\text{Bern}(p)\\)\n\\(\\{0,1\\}\\)\n\\(p(0) = 1- p\\), \\(p(1) = p\\)\n\\(p\\)\n\\(p(1-p)\\)\n\n\nBinomial: \\(\\text{Bin}(n,p)\\)\n\\(\\{0,1,\\dots,n\\}\\)\n\\(\\displaystyle\\binom{n}{x} p^x (1-p)^{n-x}\\)\n\\(np\\)\n\\(np(1-p)\\)\n\n\nGeometric: \\(\\text{Geom}(p)\\)\n\\(\\{1,2,\\dots\\}\\)\n\\((1-p)^{x-1}p\\)\n\\(\\displaystyle\\frac{1}{p}\\)\n\\(\\displaystyle\\frac{1-p}{p^2}\\)\n\n\nPoisson: \\(\\text{Po}(\\lambda)\\)\n\\(\\{0,1,\\dots\\}\\)\n\\(\\mathrm{e}^{-\\lambda} \\displaystyle\\frac{\\lambda^x}{x!}\\)\n\\(\\lambda\\)\n\\(\\lambda\\)"
  },
  {
    "objectID": "sections/L11-binomial-geometric.html#binomial",
    "href": "sections/L11-binomial-geometric.html#binomial",
    "title": "11  Binomial and geometric distributions",
    "section": "11.1 Binomial distribution",
    "text": "11.1 Binomial distribution\n\nOne family of distributions we have already seen is the Bernoulli trial \\(\\text{Bern}(p)\\), which is 1 with probability \\(p\\) and 0 with probability \\(1-p\\). We saw that this could model whether or a biased coin lands Heads, or more generally whether an experiment is successful.\n\nSuppose we toss 10 independent biased coins, each of which lands Heads with probability 0.7 and Tails with probability 0.3. What is the probability we get exactly 8 Heads altogether?\nThe probability that any specific 8 coins land Heads and the other 2 land Tails is \\(0.7^8\\times 0.3^2\\). However, there are \\(\\binom{10}{8}\\) choices for which 8 coins are the ones that land Heads. Hence, the probability is [ P() = ^8 ^2 = 0.23.]\n\nThis is a special case of the binomial distribution.\n\nLet \\(X\\) be a discrete random variable with range \\(\\{0,1,2,\\dots,n\\}\\) and PMF [ p(x) = p^x (1-p)^{n-x} . ] Then we say that \\(X\\) follows the binomial distribution with parameters \\(n\\) and \\(k\\), and write \\(X \\sim \\text{Bin}(n,p)\\).\n\nSo a binomial random variable represents the number of successes in \\(n\\) Bernoulli trials. In our previous example, the number of Heads from the coin tosses was \\(\\text{Bin}(10, 0.7)\\).\n\n\n\n\n\n\nLet \\(X \\sim \\mathrm{Bin}(8, 0.2)\\). What is (a) \\(\\mathbb P(X = 3)\\)? (b) \\(\\mathbb P(X \\geq 2)\\)?\nFor (a), we have from the definition [ P(X = 3) = 0.2^3 (1 - 0.2)^{8-3} = 5635 = 0.147 .]\nFor (b), this is an “at least” question, so it’s more convenient to look at the complementary event, \\(\\mathbb P(X < 2)\\). So \\[\\begin{align*}\n\\mathbb P(X \\geq 2) &= 1 - \\mathbb P(X < 2) \\\\\n  &= 1 - \\mathbb P(X = 0) - \\mathbb P(X = 1) \\\\\n  &= 1 - 0.8^8 - 8\\times 0.2 \\times 0.8^7 \\\\\n  &= 1 - 0.168 - 0.336 \\\\\n  & = 0.497 .\n\\end{align*}\\]\n\nWhat about the expectation and variance of a binomial random variable?\n\nLet \\(X \\sim \\text{Bin}(n, p)\\). Then\n\n\\(\\mathbb EX = np\\),\n\\(\\Var(X) =np(1-p)\\).\n\n\nOne can prove this by working out the sums – for example, the expectation is the value of the sum [ EX = _{x=0}^n x p^x (1-p)^{n-x} , ] which is a bit tricky to calculate, but not fundamentally difficult mathematics. However, in next section we will see an easier way, so we’ll reserve the proof until then instead.\nFor my 10 biased coins that are each Heads with probability \\(0.7\\), the expectation and variance are \\[\\begin{align*}\n  \\mathbb EX &= 10 \\times 0.7 = 7 \\\\\n  \\Var(X) &= 10 \\times 0.7 \\times 0.3 = 2.1\n\\end{align*}\\]"
  },
  {
    "objectID": "sections/L11-binomial-geometric.html#geometric",
    "href": "sections/L11-binomial-geometric.html#geometric",
    "title": "11  Binomial and geometric distributions",
    "section": "11.2 Geometric distribution",
    "text": "11.2 Geometric distribution\n\n\nI decide to roll a fair dice until I first roll a six, and then stop. What’s the probability I get the first six on my 5th roll of the dice?\nFor the first six to be on the 5th attempt, the first 4 rolls have to be non-sixes, and then the fifth roll has to be a six. This has probability [ ()^4 = = 0.08.]\n\nThis is a special case of the geometric distribution.\n\nLet \\(X\\) be a discrete random variable with range \\(\\{1,2,\\dots\\}\\) and PMF [ p(x) = (1-p)^{x-1}p . ] Then we say that \\(X\\) follows the geometric distribution with parameter \\(p\\), and write \\(X \\sim \\text{Geom}(p)\\).\n\nSo a geometric random variable represents the number of Bernoulli\\((p)\\) trials until the first success. In our previous example, the number of dice rolls until a six was \\(\\text{Geom}(\\frac16)\\).\n\n\n\n\n\n\nLet \\(X \\sim \\mathrm{Geom}(0.4)\\). What is (a) \\(\\mathbb P(X = 3)\\)? (b) \\(\\mathbb P(X \\geq 3)\\).\nFor part (a), we have [ P(X = 3) = (1 - 0.4)^2 = 0.144 . ]\nFor part (b), we have [ P(X ) = 1 - P(X =1) - P(X = 2) = 1 - 0.4 - (1-0.4) = 1- 0.64 = 0.36 . ]\n\n\nLet \\(X \\sim \\text{Geom}(p)\\). Then\n\n\\(\\mathbb EX = \\displaystyle\\frac1p\\),\n\\(\\Var(X) = \\displaystyle\\frac{1-p}{p^2}\\).\n\n\nSo the expected number of rolls until rolling a six is [ EX = = 6 , ] with variance [ (X) = = 30 . ]\n\nProof. (Non-examinable) For the expectation, we want to calculate [ EX = {x=1}^x (1-p)^{x-1} p = p {x=0}^x (1-p)^{x-1}. ] (We can include the \\(x = 0\\) term in the sum since it is equal to 0.)\nAt this point we will invoke the identity [ {x = 0}^x a^{x-1} = , ] which can be proved by differentiating the standard sum of a geometric progression [ {x = 0}ax = ] with respect to \\(a\\).\nUsing that identity with \\(a = 1-p\\), we get [ EX = p _{x=0}^x (1-p)^{x-1} = p, = , ] as required.\nFor the variance, we will use a trick that sometimes comes in useful, which is to start by calculating \\(\\mathbb EX(X-1)\\). Here we get [ EX(X-1) = {x=1}^x (x-1) (1-p)^{x-1} p = p(1-p) {x=0}^x(x-1) (1-p)^{x-2} . ] To calculate the sum, we note that differentiating the geometric progression formula twice gives [ {x = 0}^x(x-1) a^{x-2} = , ] so we get [ EX(X-1) = p(1-p) {x=0}^x(x-1) (1-p)^{x-2} = p(1 -p) , = . ]\nWe now want to use the computational formula \\(\\Var(X) = \\mathbb EX^2 - \\mu^2\\) to get the variance. We know \\(\\mu = 1/p\\), and from the calculation above, we have [ EX(X-1) = EX^2 - EX = EX^2 - = . ] So \\[\\begin{align*}\n\\Var(X) = \\mathbb EX^2 - \\mu^2\n&= \\left(\\frac{2(1-p)}{p^2} + \\frac{1}{p}\\right) - \\left(\\frac{1}{p}\\right)^2 \\\\\n&= \\frac{2(1-p) + p - 1}{p^2} \\\\\n&= \\frac{1-p}{p^2} .\n\\end{align*}\\]\n\nNote: Here, we defined a geometric random variable as being the number of trials up to and including the first success, which is a number in \\(\\{1, 2, \\dots\\}\\). However, some authors define it as the number of failures before the first success, which is a number in \\(\\{0, 1, 2,\\dots\\}\\). If \\(X\\) is our definition and \\(Y\\) is the second “number of failures” definition, then \\(X\\) and \\(Y+1\\) have the same distribution. Annoyingly, R uses the “number of failures before success” definition, as we will discuss in a later R worksheet."
  },
  {
    "objectID": "sections/L11-binomial-geometric.html#models",
    "href": "sections/L11-binomial-geometric.html#models",
    "title": "11  Binomial and geometric distributions",
    "section": "11.3 Distributions as models for data",
    "text": "11.3 Distributions as models for data\nFamilies of distributions – like the Bernoulli, binomial and geometric distributions we have seen so far in this module – are very useful for models in statistics. This idea is developed Bayesian statistics we will discuss in Lectures 19 and 20 of this module, and is an idea that is extremely important throughout the whole MATH1712 Probability and Statistics II.\nThe families of distributions we have looked at here are sometimes called “parametric families”, in that each of the distributions depended on one or more parameters: \\(p\\) for the Bernoulli and geometric distributions; and both \\(n\\) and \\(p\\) for the binomial distribution. (In the next lecture we will see another discrete distribution, the Poisson distribution, and later in the module we will also see some continuous parametric families: the exponential, normal and beta distributions.) This means we can adopt a model that data comes from one of the distributions within a family, then use data to estimate the value of that parameter.\nFor example:\n\nWhen testing the bias of a coin, you might assume, counting Heads as 1 and Tails as 0, that the outcome of each test is Bernoulli distributed with parameter \\(p\\), but where the value of the Heads probability \\(p\\) is unknown. You could then toss the coin many times and use this data to estimate \\(p\\).\nThe number of years between severe summer floods in a tropical climate could be modelled as geometrically distributed where the flood risk parameter \\(p\\) is unknown. By look at the gaps between severe floods in historical data, a statistician could try to estimate \\(p\\).\nA tutor might assume that the number of students that turn up to each tutorial is binomially distributed where \\(n\\) is known to be 12, the number of students assigned to the group, but \\(p\\), the “turning-up probability” is unknown. The tutor could then take records of how many students turned up to all the tutorials, and use this to estimate \\(p\\).\n\nThere are two main methods statisticians use to estimate parameters:\n\nBayesian statistics: Here, one starts with a subjective “prior” distribution for the parameters, which represents one’s personal belief about which possible values for that parameter are more or less likely before conducting any experiment. After the experiment, one then uses Bayes’ theorem to update that belief to a “posterior” distribution of one’s beliefs about the parameter given the data. The Bayesian approach will be introduced in Lecture 19 of this module.\nFrequentist statistics: Frequentist statistics does not involve any subjective prior views. Rather, frequentism is about assessing the extent to which the data is consistent with certain hypotheses. For example, one might try to find the value for the parameter that would seem “most consistent” with the data, and use that as an “estimate” of the parameter: “My best guess of the Heads probability \\(p\\) of the coin is \\(p = 0.53\\).” Alternatively, one might find a range of values for the parameter that are all at least somewhat consistent with the data: “I am confident the value of the Heads probability lies in the range \\(0.49 \\leq p \\leq 0.57\\), as these values are all consistent with the data.” Third, one could text if a specific hypothesis is consistent with the data or not: “The data is consistent with the hypothesis that \\(p = 0.50\\), whih would mean the coin is fair, so I have no strong evidence for disbelieving that.” The frequentist approach will pursued in detail in MATH1712."
  },
  {
    "objectID": "sections/L11-binomial-geometric.html#summary-L11",
    "href": "sections/L11-binomial-geometric.html#summary-L11",
    "title": "11  Binomial and geometric distributions",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\n\n\nDistribution\nRange\nPMF\nExpectation\nVariance\n\n\n\n\nBernoulli: \\(\\text{Bern}(p)\\)\n\\(\\{0,1\\}\\)\n\\(p(0) = 1- p\\), \\(p(1) = p\\)\n\\(p\\)\n\\(p(1-p)\\)\n\n\nBinomial: \\(\\text{Bin}(n,p)\\)\n\\(\\{0,1,\\dots,n\\}\\)\n\\(\\displaystyle\\binom{n}{x} p^x (1-p)^{n-x}\\)\n\\(np\\)\n\\(np(1-p)\\)\n\n\nGeometric: \\(\\text{Geom}(p)\\)\n\\(\\{1,2,\\dots\\}\\)\n\\((1-p)^{x-1}p\\)\n\\(\\displaystyle\\frac{1}{p}\\)\n\\(\\displaystyle\\frac{1-p}{p^2}\\)"
  }
]