<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MATH1710 Probability and Statistics 1 - 18&nbsp; Limit theorems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../sections/L19-bayes-idea.html" rel="next">
<link href="../sections/L16-exponential-multi.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Limit theorems</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">MATH1710</a> 
        <div class="sidebar-tools-main">
    <a href="../MATH1710-Probability-and-Statistics-1.pdf" title="Download PDF" class="sidebar-tool px-1"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../about.html" class="sidebar-item-text sidebar-link">About MATH1710</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Exploratory data analysis</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L01-stats.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Summary statistics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L02-dataviz.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data visualisations</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Probability</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L03-events.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Sample spaces and events</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L04-probability.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L05-classical-i.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Classical probability I</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L06-classical-ii.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Classical probability II</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L07-conditional.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Independence and conditional probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L08-two-theorems.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Two theorems on conditional probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L09-discrete-rv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Discrete random variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L10-expectation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Expectation and variance</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L11-binomial-geometric.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Binomial and geometric distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L12-poisson.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Poisson distribution</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L13-multi-rv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Multiple random variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L14-covariance.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Expectation and covariance</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L15-continuous.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Continuous random variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L17-normal.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Normal distribution</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L16-exponential-multi.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Exponential distribution and multiple continuous random variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L18-limit.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Limit theorems</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Bayesian statistics</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L19-bayes-idea.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">The Bayesian idea</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L20-bayes-models.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">More Bayesian models</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">Other stuff</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L21-summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">All questions answered</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/L22-exam.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Exam</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../R/R.html" class="sidebar-item-text sidebar-link">R Worksheets</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../writing.html" class="sidebar-item-text sidebar-link">Tips on writing mathematics</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#lln" id="toc-lln" class="nav-link active" data-scroll-target="#lln"><span class="toc-section-number">18.1</span>  Law of large numbers</a></li>
  <li><a href="#clt" id="toc-clt" class="nav-link" data-scroll-target="#clt"><span class="toc-section-number">18.2</span>  Central limit theorem</a></li>
  <li><a href="#normal-approx" id="toc-normal-approx" class="nav-link" data-scroll-target="#normal-approx"><span class="toc-section-number">18.3</span>  Approximations with the normal distribution</a></li>
  <li><a href="#summary-09" id="toc-summary-09" class="nav-link" data-scroll-target="#summary-09">Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="L18-limit" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Limit theorems</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="mysummary">
<p>There will be no lecture on Wednesday 30 November, as <a href="https://www.leedsucu.org.uk/information-for-students-2/">the UCU are on strike</a>. Instead, you should learn the material that would have been given in the lecture from these notes. This material is fully examinable, as much as any other lecture.</p>
<p>I have provided some old pandemic-era videos embedded in these notes, which may help you – the section numbering has changed since these videos were made, but the material is mostly the same. Drop-in sessions are available on Thursday (2pm in <a href="https://mpaldridge.github.io/office.html">PRD 9.320</a> and 4pm in Roger Stevens LT17) if you struggle with anything in this lecture.</p>
</div>
<section id="lln" class="level2" data-number="18.1">
<h2 data-number="18.1" class="anchored" data-anchor-id="lln"><span class="header-section-number">18.1</span> Law of large numbers</h2>
<div class="videowrap">
<div class="videowrapper">
<iframe src="https://www.youtube.com/embed/u4hJv2sDUoc">
</iframe>
</div>
</div>
<p>In this lecture we will look at some “limit” results; that is, results about a large number of <span class="math inline">\(n\)</span> of random variables, as <span class="math inline">\(n\)</span> tends to infinity. We will be looking at the case when the random variables are independent and identically distributed (IID), which represents the case of multiple repeated experiments.</p>
<p>So let <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> be a sequence of IID random variables. Let us write <span class="math inline">\(\mu = \mathbb EX_1\)</span> for the common expectation and <span class="math inline">\(\sigma^2 = \Var(X_1)\)</span> for the common variance.</p>
<p>At the beginning of the course, we saw the mean of some values <span class="math inline">\(x_1, x_2, \dots, x_n\)</span> was [ x = (x_1 + x_2 + + x_n) = <em>{i=1}^n x_i ; ] that is, what we get if we add them up and divide by <span class="math inline">\(n\)</span>. In the same way, we could calculate the “mean” of some random variables <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> by adding them up and dividing by <span class="math inline">\(n\)</span>; that is: [ X_n = (X_1 + X_2 + + X_n) = </em>{i=1}^n X_i . ] (The subscript <span class="math inline">\(n\)</span> on “<span class="math inline">\(\overline X_n\)</span>” is just to remind us this is a mean of <span class="math inline">\(n\)</span> random variables.)</p>
<p>Here, each of the <span class="math inline">\(X_i\)</span>s is a random variable, so their mean <span class="math inline">\(\overline X_n\)</span> is another random variable too. This mean random variable <span class="math inline">\(\overline X_n\)</span> will be out main object in this lecture. We can ask questions about the random variable <span class="math inline">\(\overline X_n\)</span> just the same as we would ask about any other random variable. For example: What is its expectation and variance?</p>
<p>The expectation of <span class="math inline">\(\bar X_n\)</span> is <span class="math display">\[\begin{align*}
\mathbb E \overline X_n &amp;= \mathbb E \left( \frac{1}{n} (X_1 + X_2 + \cdots + X_n)\right) \\
&amp;=   \frac{1}{n} (\mathbb EX_1 + \mathbb EX_2 + \cdots + \mathbb EX_n)\\
&amp;= \frac{1}{n} (\mu + \mu + \cdots + \mu)\\
&amp;= \frac{1}{n} n \mu \\
&amp;= \mu .
\end{align*}\]</span> Here we used linearity of expectation to take the <span class="math inline">\(1/n\)</span> out of the brackets and to add up the individual expectations.</p>
<p>In the same way, the variance of <span class="math inline">\(\overline X_n\)</span> is <span class="math display">\[\begin{align*}
\Var( \overline X_n) &amp;= \Var \left( \frac{1}{n} (X_1 + X_2 + \cdots + X_n)\right) \\
&amp;= \left(\frac{1}{n}\right)^2 \Var(X_1 + X_2 + \cdots + X_n) \\
&amp;=   \frac{1}{n^2} \big(\Var(X_1) + \Var(X_2) + \cdots + \Var (X_n)\big)\\
&amp;= \frac{1}{n^2} (\sigma^2 + \sigma^2+ \cdots + \sigma^2)\\
&amp;= \frac{1}{n^2} n \sigma^2 \\
&amp;= \frac{\sigma^2}{n} .
\end{align*}\]</span> Here, we crucially used the fact that the random variables are independent to write the variance of the sum as a sum of the variances.</p>
<p>In conclusion we have this:</p>
<div class="theorem">
<p>Let <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> be a sequence of IID random variables, and write <span class="math inline">\(\mu = \mathbb EX_1\)</span> for the common expectation and <span class="math inline">\(\sigma^2 = \Var(X_1)\)</span> for the common variance. Further, write <span class="math inline">\(\overline X_n =\frac{1}{n} \sum_{i=1}^n X_i\)</span> for the mean of these random variables. Then [ E X_n = (X_n) = . ]</p>
</div>
<p>Now think about what happens to this mean <span class="math inline">\(\overline X_n\)</span> when <span class="math inline">\(n\)</span> gets very large. We see that the expectation <span class="math inline">\(\mathbb E\overline X_n = \mu\)</span> stays the same, but the variance <span class="math inline">\(\Var(\overline X_n) = \sigma^2/n\)</span> gets smaller and smaller as <span class="math inline">\(n\)</span> gets bigger. So the range of probable values for <span class="math inline">\(\overline X_n\)</span> will be squeezing tighter and tighter around <span class="math inline">\(\mu\)</span>. Given that, it seems as if (and it can be rigorously proven that) we have the “law of large numbers”.</p>
<div id="thLLN" class="theorem" name="Law of large numbers">
<p>Let <span class="math inline">\(X_1, X_2, \dots\)</span> be a sequence of IID random variables. Write <span class="math inline">\(\mu = \mathbb EX_1\)</span> for the common expectation and <span class="math inline">\(\overline X_n =\frac{1}{n} \sum_{i=1}^n X_i\)</span> for the mean of the first <span class="math inline">\(n\)</span> random variables. Then [ X_n ; ] by which we mean that, for any <span class="math inline">\(\epsilon &gt; 0\)</span>, [ P(|X_n - | &gt; ) ]</p>
</div>
<p>The precise mathematical definition of the convergence is not important here. What is important is the general principle that the mean <span class="math inline">\(\overline X_n\)</span> is overwhelmingly likely to get closer and closer to the expectation <span class="math inline">\(\mathbb EX = \mu\)</span>. In other words, the expectation <span class="math inline">\(\mathbb EX = \mu\)</span> represents the “long-run average” of independent experiments – this justifies referring to the expectation as a kind of average.</p>
<p>One special case is if we have repeated experiments that succeed with probability <span class="math inline">\(p\)</span>; that is, <span class="math inline">\(X_n \sim \text{Bern}(p)\)</span>. Then the law of large numbers says that the long-run proportion of successes is [ _{i = 1}^n X_n = X_n EX_1 = p . ] So the long-run proportion of times an event happens converges to its probability. This goes back to what we said about “frequentist probability” <a href="#what-is-prob">right at the beginning of Lecture 3</a>: that one way to understand the probability of an event is as the long-run frequency of its occurrence.</p>
</section>
<section id="clt" class="level2" data-number="18.2">
<h2 data-number="18.2" class="anchored" data-anchor-id="clt"><span class="header-section-number">18.2</span> Central limit theorem</h2>
<div class="videowrap">
<div class="videowrapper">
<iframe src="https://www.youtube.com/embed/yygv7L5hcOg">
</iframe>
</div>
</div>
<p>We have seen that if the <span class="math inline">\(X_i\)</span> are IID random variables with expectation <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, then [ EX_n = (X_n) = ] and the law of large numbers tells us that <span class="math inline">\(\overline X_n \to \mu\)</span> as <span class="math inline">\(n \to \infty\)</span>. Alternatively, we could say that <span class="math inline">\(\overline X_n - \mu \to 0\)</span>.</p>
<p>We might also want to know what the variation of <span class="math inline">\(\overline X_n - \mu\)</span> is around 0. Obviously, the law of large numbers tells us this variation shrinks away to 0, but we might be interested in the “shape” of that variation as it shrinks away. To study this variation, we need to “re-inflate” it, to stop it disappearing. It turns out that the correct way to do this is by multiplying by <span class="math inline">\(\sqrt{n}\)</span> and looking at <span class="math inline">\(\sqrt{n}(\overline X_n - \mu)\)</span>.</p>
<p>It’s fairly easy to check that the expectation and variance of the “re-inflated variation” is <span class="math display">\[\begin{align*}
\mathbb E\sqrt{n} (\overline X_n - \mu) &amp;= \sqrt{n}(\mu - \mu) = 0 \\
\Var\big(\sqrt{n} (\overline X_n - \mu)\big) &amp;= (\sqrt n)^2 \, \frac{\sigma^2}{n} = \sigma^2 .
\end{align*}\]</span> So whatever distribution <span class="math inline">\(\sqrt{n}(\overline X_n - \mu)\)</span> has, that distribution must have expectation <span class="math inline">\(0\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. But in fact, <em>no matter what distribution the <span class="math inline">\(X_i\)</span> have</em> and regardless of whether they are discrete or continuous, this “variation around 0” <span class="math inline">\(\sqrt{n}(\overline X_n - \mu)\)</span> always gets closer and closer to the normal distribution!</p>
<div id="thCLT" class="theorem" name="Central limit theorem">
<p>Let <span class="math inline">\(X_1, X_2, \dots\)</span> be a sequence of IID random variables. Write <span class="math inline">\(\mu = \mathbb EX_1\)</span> for the common expectation, <span class="math inline">\(\sigma^2 = \Var(X_1)\)</span> for the common variance, and <span class="math inline">\(\overline X_n =\frac{1}{n} \sum_{i=1}^n X_i\)</span> for the mean of the first <span class="math inline">\(n\)</span> random variables. Then [ (X_n - ) N(0, ^2) ; ] by which we mean that, if <span class="math inline">\(Y \sim \mathrm N(0, \sigma^2)\)</span>, then, for all <span class="math inline">\(a &lt; b\)</span>, [ P(a (X_n - ) b ) P(a Y b) ]</p>
</div>
<p>(A full proof of the central limit theorem is too complicated to include here.)</p>
<p>Another alternative way to write this is to divide both sides by <span class="math inline">\(\sigma\)</span> and write it as [ N(0, 1) . ]</p>
<p>The result we have stated, for IID random variables, is the most important case of the central limit theorem. But central limit theorems can be proved for other cases too – the rough principle is that if you have lots of random variables most of which are independent (or only weakly dependent) and none of which are individually too big, then the mean or sum will be approximately normally distributed.</p>
</section>
<section id="normal-approx" class="level2" data-number="18.3">
<h2 data-number="18.3" class="anchored" data-anchor-id="normal-approx"><span class="header-section-number">18.3</span> Approximations with the normal distribution</h2>
<div class="videowrap">
<div class="videowrapper">
<iframe src="https://www.youtube.com/embed/OYv464S0fDI">
</iframe>
</div>
</div>
<p>There are many other distributions <span class="math inline">\(X\)</span> that can be well approximated by a normal distribution where <span class="math inline">\(\mu\)</span> is set to <span class="math inline">\(\mathbb EX\)</span> and <span class="math inline">\(\sigma^2\)</span> is set to <span class="math inline">\(\Var(X)\)</span>. Using intuition from the central limit theorem, this is roughly when the distribution can be expressed as the accumulation of many small effects.</p>
<ul>
<li>A binomial distribution <span class="math inline">\(X \sim \mathrm{Bin}(n, p)\)</span> is well approximated by a normal distribution <span class="math inline">\(\mathrm{N}(np, np(1-p))\)</span> when <span class="math inline">\(n\)</span> is large and <span class="math inline">\(p\)</span> is not too close to 0 or 1. (When <span class="math inline">\(p\)</span> is small, we already know that the Poisson distribution is a good approximation.)</li>
<li>A Poisson distribution <span class="math inline">\(X \sim \mathrm{Po}(\lambda)\)</span> is well approximated by a normal distribution <span class="math inline">\(\mathrm{N}(\lambda, \lambda)\)</span> when <span class="math inline">\(\lambda\)</span> is large.</li>
<li>A sum <span class="math inline">\(Y = X_1 + \cdots + X_n\)</span> of <span class="math inline">\(n\)</span> IID geometric distributions <span class="math inline">\(X_1, \dots, X_n \sim \mathrm{Geom}(p)\)</span> (sometimes known as a “negative binomial” distribution) is well approximated by a normal distribution <span class="math inline">\(\mathrm{N}(n/p, np/(1-p)^2)\)</span> when <span class="math inline">\(n\)</span> is large and <span class="math inline">\(p\)</span> is not to close to 1.</li>
<li>A sum <span class="math inline">\(Y = X_1 + \cdots + X_n\)</span> of <span class="math inline">\(n\)</span> IID exponential distributions <span class="math inline">\(X_1, \dots, X_n \sim \mathrm{Exp}(\lambda)\)</span> (sometimes known as a “Gamma” distribution) is well approximated by a normal distribution <span class="math inline">\(\mathrm{N}(n/\lambda, n/\lambda^2)\)</span> when <span class="math inline">\(n\)</span> is large and the expectation <span class="math inline">\(1/\lambda\)</span> is not too small.</li>
</ul>
<p>We already know, of course, that a sum of independent normal distributions is <em>exactly</em> normal, with no approximations needed.</p>
<div class="example">
<p><em>Suppose I toss 1000 coins. What’s the probability I get between 495 and 505 Heads?</em></p>
<p>The true distribution of Heads is <span class="math inline">\(X \sim \mathrm{Bin}(1000, \frac12)\)</span>, and the question wants [ P(495 X ) = _{x = 495}^{505} p_X(x) . ] We can calculate the exact answer using R:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dbinom</span>(<span class="dv">495</span><span class="sc">:</span><span class="dv">505</span>, <span class="dv">1000</span>, <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2720284</code></pre>
</div>
</div>
<p>However, we could instead use a normal approximation (which, again, would be useful in Victorian times or in an exam). Since <span class="math inline">\(\mathbb EX = 1000 \times \frac12 = 500\)</span> and <span class="math inline">\(\Var(X) = 1000 \times \frac12 \times \frac12 = 250\)</span>, we have the normal approximation <span class="math inline">\(Y \sim \mathrm N(500, 250)\)</span>. The figure below shows the PMF of the discrete distribution <span class="math inline">\(X \sim \mathrm{Bin}(1000, \frac12)\)</span> (blue bars) and the PDF of the continuous approximation <span class="math inline">\(Y\sim \mathrm N(500, 250)\)</span> (red line) between 450 and 550 – it is an extremely close match!</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="L18-limit_files/figure-html/norm-bin-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We could then calculate [ P(495 X ) P(495 Y ) . ] We could standardise and use the statistical tables, or just use R:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">505</span>, <span class="dv">500</span>, <span class="fu">sqrt</span>(<span class="dv">250</span>)) <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="dv">495</span>, <span class="dv">500</span>, <span class="fu">sqrt</span>(<span class="dv">250</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2481704</code></pre>
</div>
</div>
<p>This is not too far off the correct answer <span class="math inline">\(0.272\)</span> we calculated exactly, but it does miss by about 9%.</p>
<p>Note, though, that we approximated the discrete random variable <span class="math inline">\(X\)</span> by a continuous random variable <span class="math inline">\(Y\)</span>. So the next possibility for <span class="math inline">\(X\)</span> above 505 was 506 and below 495 was 494, whereas <span class="math inline">\(Y\)</span> could smoothly vary between the two. So we usually get a more accurate approximation if we use a <strong>continuity correction</strong> and round outwards halfway to the next discrete point. So we should get a better approximation from [ P(495 X ) P(494.5 Y ) . ]</p>
<p>Calculating this in R (or with statistical tables) we get</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="fl">505.5</span>, <span class="dv">500</span>, <span class="fu">sqrt</span>(<span class="dv">250</span>)) <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">494.5</span>, <span class="dv">500</span>, <span class="fu">sqrt</span>(<span class="dv">250</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2720476</code></pre>
</div>
</div>
<p>Using the continuity correction, we now have an incredibly accurate approximation – it only misses by 0.006%.</p>
</div>
<p>Whenever we approximate a discrete random variable by a continuous random variable (such as a normal distribution), using a continuity correction – that is, rounding halfway to the next discrete point – typically makes the approximation more accurate. If <span class="math inline">\(X\)</span> is a discrete random variable that takes integer values and <span class="math inline">\(Y\)</span> is a continuous approximation, then the appropriate continuity corrections are <span class="math display">\[\begin{align*}
\mathbb P(X \leq n) &amp;\approx \mathbb P(Y \leq n + \tfrac12) &amp; \mathbb P(X \geq n) &amp;\approx \mathbb P(Y \geq n - \tfrac12) \\
\mathbb P(X &lt; n) &amp;\approx \mathbb P(Y &lt; n - \tfrac12) &amp; \mathbb P(X &gt; n) &amp;\approx \mathbb P(Y &gt; n + \tfrac12)
\end{align*}\]</span></p>
</section>
<section id="summary-09" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="summary-09">Summary</h2>
<div class="mysummary">
<ul>
<li>If <span class="math inline">\(\overline X_n\)</span> is the mean of <span class="math inline">\(n\)</span> IID random variables with expectation <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, then <span class="math inline">\(\mathbb E\overline X_n = \mu\)</span> and <span class="math inline">\(\Var(\overline X_n) = \sigma^2/n\)</span>.</li>
<li>The law of large numbers says that <span class="math inline">\(\overline X_n \to \mu\)</span>.</li>
<li>The central limit theorem says that <span class="math inline">\(\sqrt{n}(\overline X_n - \mu) \to \text{N}(0, \sigma^2)\)</span>.</li>
</ul>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../sections/L16-exponential-multi.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Exponential distribution and multiple continuous random variables</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../sections/L19-bayes-idea.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">The Bayesian idea</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>