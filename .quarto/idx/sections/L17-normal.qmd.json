{"title":"Normal distribution","markdown":{"headingText":"Normal distribution ","headingAttr":{"id":"L16-normal","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\nWhen we studied discrete random variables, we studied a number of important families of distributions: the Bernoulli, binomial, geometric, and Poisson distributions. In this lecture, we'll look at an extremely important distribution: the \"normal\" (or \"Gaussian\") distribution.\n\n## Definition of the normal distribution  {#normal-definition}\n\n<!--\n:::: {.videowrap}\n::: {.videowrapper}\n<iframe src=\"https://www.youtube.com/embed/of84BBnJdgw\"></iframe>\n:::\n::::\n\n\nThere's one very important distribution we need to talk about, which is the so-called \"normal\" (or \"Gaussian\") distribution.\n-->\n\n::: {.definition}\nIf $X$ is a continuous random variable with PDF\n\\[ f_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp \\left( - \\frac{(x - \\mu)^2}{2\\sigma^2} \\right) , \\]\nthen we say that $X$ has the **normal distribution** with expectation $\\mu$ and variance $\\sigma^2 > 0$, and write $X \\sim \\mathrm N(\\mu,\\sigma^2)$.\n:::\n\n(Many people call $\\mu$ the \"mean\", which is a slight misnomer.)\n\nThis PDF is the famous \"bell curve\", where the centre of the bell is at $x = \\mu$ and the width of the bell is controlled by the value of $\\sigma^2$. Note also that the PDF is symmetric about $\\mu$.\n\n```{r norm-pic-1, cache = TRUE, echo = FALSE}\ncurve(dnorm(x, 3, 1), type = \"l\", n = 1001, lwd = 2, col = \"green\", from = -6, to = 6, xlim = c(-5, 5), ylab = \"probability density function f(x)\")\ncurve(dnorm(x, 0, 2), type = \"l\", n = 1001, lwd = 2, col = \"red\", from = -6, to = 6, add = TRUE)\ncurve(dnorm(x, 0, 1), type = \"l\", n = 1001, lwd = 2, col = \"blue\", from = -6, to = 6, add = TRUE)\nlegend(\"topleft\", c(\"N(0, 1)\", \"N(0, 4)\", \"N(3, 1)\"), col = c(\"blue\", \"red\", \"green\"), lwd = 2)\n```\n\n```{r norm-pic-2, cache = TRUE, echo = FALSE}\ncurve(dnorm(x, 0, 1), type = \"l\", n = 1001, lwd = 2, col = \"blue\", from = -4, to = 4, xlab = \"\", ylab = \"\", xlim = c(-3, 3), axes = FALSE)\naxis(1, at = c(-4,0,4), labels = c(\"\",expression(mu),\"\"), lwd = 2)\narrows(0, 0, 0, 1/sqrt(2*pi), code = 0, lty = 2, col = \"red\")\narrows(-1, exp(-1/2)/sqrt(2*pi), 0, exp(-1/2)/sqrt(2*pi), length = 0.15, code = 3, lwd = 2)\narrows(0, exp(-1/2)/sqrt(2*pi), 1, exp(-1/2)/sqrt(2*pi), length = 0.15, code = 3, lwd = 2)\ntext(-0.5, 0.22, expression(sigma))\ntext( 0.5, 0.22, expression(sigma))\n```\n\nOne important special case is $\\mu = 0$ and $\\sigma^2 = 1$, in which case we say that $Z \\sim \\mathrm N(0,1)$ has the **standard normal distribution**. We typically write $\\phi$ (lower-case \"phi\"), where \n\\[ \\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\mathrm e^{-z^2/2} \\]\nfor the PDF of a standard normal distribution, and write $\\Phi$ (upper-case \"Phi\"), where\n\\[ \\Phi(z) = \\mathbb P(Z \\leq z) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^z \\mathrm e^{-y^2/2}\\, \\mathrm dy \\]\nfor the CDF of a standard normal distribution.\n\nThe normal distribution is a very widely used distribution for modelling many things in real life.\n\n* Measurement error with scientific instruments is typically modelled as a normal distribution with expectation $\\mu = 0$. The more precise the instrument, the lower the value of the variance $\\sigma^2$.\n* According to [a poll a few years ago](http://www1.maths.leeds.ac.uk/~voss/2019/MATH1712/index.html), the height of MATH1712 students in centimetres can be modelled well by a normal distribution with expectation $\\mu = 172$ and variance $\\sigma^2 = 86$.\n* In financial models, it is often assumed that the logarithm of the daily change in a stock price follows a normal distribution. In this context, the expectation $\\mu$ is known as the \"drift\" and the standard deviation $\\sigma$ as the \"volatility\". This \"log-normal\" model is the basis of the famous Black--Scholes model of financial markets.\n\nMore generally, and for reasons we will come back to later, the normal distribution is good for modelling things where lots of little effects add together to make a bigger effect. We will also see later that many other distributions can be approximated by a normal distribution.\n\nIt's generally difficult, or even impossible, to directly calculate probabilities of events concerning the normal distribution. Instead, one must use numerical approximations. We will discuss these further later in this section.\n\n\n\n\n## Properties of the normal distribution {#normal-properties}\n\n<!--\n:::: {.videowrap}\n::: {.videowrapper}\n<iframe src=\"https://www.youtube.com/embed/4P6Xe1BbMn0\"></iframe>\n:::\n::::\n-->\n\n::: {.theorem #norm-prop}\nLet $X \\sim \\mathrm{N}(\\mu, \\sigma^2)$ be a normally distributed random variable. Then:\n\n1. $f_X(x)$ is indeed a PDF, in that $\\displaystyle\\int_{-\\infty}^\\infty f_X(x)\\,\\mathrm dx = 1$;\n2. $\\mathbb EX = \\mu$;\n3. $\\Var(X) = \\sigma^2$.\n\nIn particular, if $Z \\sim \\mathrm{N}(0, 1)$ is a standard normal distribution, then $\\mathbb EZ = 0$ and $\\Var(Z) = 1$.\n:::\n\nWe'll give (non-examinable) proofs of these soon. But first we'll note one other thing.\n\nLet $X \\sim \\mathrm{N}(\\mu, \\sigma^2)$, and consider the random variable $Y = aX + b$. Then we know that\n\\begin{align*}\n\\mathbb E(aX + b) &= a\\mu + b , \\\\\n\\Var(aX + b) &= a^2 \\sigma^2 .\n\\end{align*}\nIn fact, it can be shown that $aX + b$ is normally distributed too; that is, $aX + b \\sim \\mathrm{N}(a\\mu + b, a^2 \\sigma^2)$. Importantly, if we take $a = 1/\\sigma$ and $b = -\\mu/\\sigma$, then we see that\n\\[ Z = \\frac{X - \\mu}{\\sigma} \\sim \\text{N} (0, 1) . \\]\nIn other words, we can stretch and scale any normal random variable to turn it into a standard normal random variable. This is known as \"standardisation\" and will be useful later.\n\nWe can also use standardisation to help us prove Theorem \\@ref(thm:norm-prop).\n\n::: {.proof}\n*(Non-examinable)* By using standardisation, it suffices to prove the theorem for a standard normal random variable $X \\sim \\mathrm{N}(0,1)$.\n\nFor part 1, we need to show that\n\\[ I = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^\\infty \\mathrm e^{-x^2/2}\\, \\mathrm dx = 1 . \\]\nTo prove this we use one of the most outrageous tricks in mathematics! The first part of the trick is that, instead of calculating the integral itself $I$, we can instead calculate the square of the integral $I^2$, which we also need to show is equal to 1. This is\n\\begin{align*}\n  I^2 &= \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^\\infty \\mathrm e^{-x^2/2}\\, \\mathrm dx \\times \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^\\infty \\mathrm e^{-y^2/2}\\, \\mathrm dy\\\\\n    &= \\frac{1}{2\\pi} \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty  \\mathrm e^{-x^2/2}\\,\\mathrm e^{-y^2/2} \\, \\mathrm dx\\, \\mathrm dy \\\\\n    &= \\frac{1}{2\\pi} \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty  \\mathrm e^{-(x^2+y^2)/2}\\,\\mathrm dx\\, \\mathrm dy .\n\\end{align*}\nThe second part of the outrageous trick is notice that the appearance of $x^2 + y^2$ suggests it might be useful to transfer from cartesian coordinates $(x,y)$ to polar coordinates $(r, \\theta)$. Recalling that $x^2 + y^2 = r^2$ and $\\mathrm dx\\, \\mathrm dy = r\\, \\mathrm dr \\,\\mathrm d\\theta$, we have\n\\begin{align*}\n  I^2 &= \\frac{1}{2\\pi} \\int_{0}^{2\\pi} \\int_{0}^\\infty  \\mathrm e^{-r^2/2}\\,r\\,\\mathrm dr\\, \\mathrm d\\theta \\\\\n    &= \\frac{1}{2\\pi} \\, 2\\pi\\int_{0}^\\infty  r\\, \\mathrm e^{-r^2/2}\\,\\mathrm dr \\\\\n    &= \\left[ -\\mathrm e^{-r^2/2} \\right]_0^\\infty \\\\\n    &= - 0 -(-1) \\\\\n    &= 1 ,\n\\end{align*}\nand we're done.\n\nFor part 2, we need to show that $\\mathbb EX = 0$. We have\n\\begin{align*}\n\\mathbb EX &= \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} x\\,  \\mathrm e^{-x^2/2}\\, \\mathrm dx \\\\\n  &= \\frac{1}{\\sqrt{2\\pi}} \\left[-\\mathrm e^{-x^2/2}\\right]_{-\\infty}^\\infty \\\\\n  &= -0 - (-0) \\\\\n  &= 0 ,\n\\end{align*}\nas required.\n\nFor part 3, we need to show that $\\mathbb EX^2 = 1$. Using integration by parts with $u = x$, $v' = x\\,\\mathrm e^{-x^2/2}$, we have\n\\begin{align*}\n\\mathbb EX^2 &= \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} x^2\\,  \\mathrm e^{-x^2/2}\\, \\mathrm dx \\\\\n  &= \\frac{1}{\\sqrt{2\\pi}} \\left[-x \\mathrm e^{-x^2/2}\\right]_{-\\infty}^\\infty + \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^\\infty \\mathrm e^{-x^2/2} \\, \\mathrm dx \\\\\n  &= 0 + \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^\\infty \\mathrm e^{-x^2/2} \\, \\mathrm dx .\n\\end{align*}\nBut this integral on the right is just the integral $I$ of the PDF as above, which we know equals 1, as required.\n:::\n\nThere is one last property of the normal distribution that we won't use directly in this module, but is perhaps worth knowing anyway.\n\n::: {.theorem}\nIf $X \\sim \\mathrm{N}(\\mu_X, \\sigma^2_X)$ and $Y\\sim \\mathrm{N}(\\mu_Y, \\sigma^2_Y)$ are independent, then\n\\[ X+Y \\sim \\mathrm{N}(\\mu_X + \\mu_Y, \\sigma^2_X+\\sigma^2_Y) . \\]\n:::\n\n## Calculations using R  {#normal-r}\n\nWe will try to answer a number of questions about the normal distribution.\n\n::: {.thpart}\n**Question 1.**  *A fiberoptic fibre is manufactured with an average width of 8 nanometres (nm), with a standard deviation of 0.04 nm. Fibres that are wider than 8.1 nm fail testing and must be discarded. If the manufactured width is modelled as normally distributed, then what proportion of fibres pass the test?*\n\nLet $X \\sim \\mathrm{N}(8, 0.04^2)$ denote the width of a random fibre, measured in nanometres. Then this question required us to find\n\\[ F(8.15) = \\mathbb P(X \\leq 8.1) = \\frac{1}{\\sqrt{2\\pi\\times 0.04^2}} \\int_{-\\infty}^{8.1} \\exp \\left(-\\frac{(x - 8)^2}{2\\times 0.04^2} \\right) \\, \\mathrm dx . \\]\n\nUnfortunately, it is not possible to calculate this integral exactly. However, computers can approximate this integral very accurately and very quickly. In R, this is done with the `pnorm()` function, which calculates the CDF of a normal distribution. `pnorm()` typically takes three arguments:\n\n1. the first argument is the value $x$ at which we wish to evaluate the CDF;\n1. the second argument is the expectation $\\mu$ of the normal distribution;\n1. the third argument is the standard deviation $\\sigma$ of the normal distribution. (Note that this third argument is the *standard deviation* $\\sigma$ and not the variance $\\sigma^2$. This is an easy mistake to make!)\n\nSo here, the number we want is \n\n```{r}\npnorm(8.1, 8, 0.04)\n```\n\nWe see that roughly 99.4% of fibres pass the test.\n:::\n\n::: {.thpart}\n**Question 2.**  *Let $Z \\sim \\mathrm{N}(0,1)$. What is $\\mathbb P(Z \\leq 1.45)$?*\n\nThis is asking for $\\Phi(1.45) = \\mathbb P(Z \\leq 1.45)$. This is:\n\n```{r}\npnorm(1.45, 0, 1)\n```\n\nBut in fact, the standard normal distribution CDF $\\Phi$ is so common that R allows you to omit the values of $\\mu$ and $\\sigma$ if they are 0 and 1 respectively. So you can save yourself a few keystrokes by simply writing:\n\n```{r}\npnorm(1.45)\n```\n:::\n\n::: {.thpart}\n**Question 3.**  *Let $Z \\sim \\mathrm{N}(0,1)$. What is $\\mathbb P(Z > 0.33)$?*\n\nThis is asking for the upper-tail probability. The direct way to get R to solve this is to use the `lower.tail = FALSE` option that we discussed in [R Worksheet 7](#r-work). That is, we use:\n\n```{r}\npnorm(0.33, lower.tail = FALSE)\n```\n\nAlternatively, we could use the fact that $\\mathbb P(Z > z) = 1 - \\mathbb P(Z \\leq z) = 1 - \\Phi(z)$. Then we could equally well calculate this as\n\n```{r}\n1 - pnorm(0.33)\n```\n:::\n\n::: {.thpart}\n**Question 4.** *We return to the fiberoptic model $X \\sim \\mathrm{N}(8, 0.04^2)$ from Question 1. Fibres can be awarded a special \"high quality\" stamp if their width is between 7.95 and 8.05 nm. What proportion of these fibres qualify?*\n\nThis is asking for $\\mathbb P(7.95 \\leq X \\leq 8.05)$. But we can calculate this as\n\\[ \\mathbb P(7.95 \\leq X \\leq 8.05) = \\mathbb P(X \\leq 8.05) - \\mathbb P(X < 7.95) = F(8.05) - F(7.95) .\\]\n(Formally, this is because\n\\[ \\{X < 7.95\\} \\cup \\{7.95 \\leq X \\leq 8.05\\} = \\{X \\leq 8.05\\} \\]\nis a disjoint union, so we can use Axiom 3.)\n\nSo the proportion of qualifying fibres is\n\n```{r}\nmu <- 8\nsigma <- 0.04\npnorm(8.05, mu, sigma) - pnorm(7.95, mu, sigma)\n```\n\nor about 79%.\n:::\n\n\n::: {.thpart}\n**Question 5.** *We stay with the fiberoptic model $X \\sim \\mathrm{N}(8, 0.04^2)$ from Questions 1 and 4. The manufacturer wants to be able to advertise that 99.9% of their fibres are between lower and upper limits $x$ and $y$. What values of $x$ and $y$ can they promise?*\n\nIs $F$ is the CDF of this distribution, then we are looking for $x$ and $y$ such that $F(x) = 0.0005$ and $F(y) = 0.9995$. That way, $F(y) - F(x) = 0.999$, so we have 99.9% of fibres within that interval and 0.05% outside either side.\n\nYou may remember from R Worksheet 7 that the inverse $F^{-1}$ of the CDF is called the **quantile function**. Here, we want $F^{-1}(0.0005)$ and $F^{-1}(0.9995)$. The quantile function for the normal distribution in R is `qnorm()`. (It also has a `lower.tail = FALSE` option, which is sometimes useful.) So we can use\n\n```{r}\nmu <- 8\nsigma <- 0.04\nc(qnorm(0.0005, mu, sigma), qnorm(0.9995, mu, sigma))\n```\n\nWe see that we can guarantee that 99.9% of fibres are between roughly 7.87 and 8.13 nm wide.\n:::\n\n## Calculations using statistical tables  {#normal-tables}\n\nDoing normal calculations with R is all very well. But what if you accidentally built a time machine and got transported back to Victorian times. Then how would you perform calculations with the normal distribution?\n\nIn the olden days, someone would (using some enormous computer the size of a room, or whatever) calculate lots of values of $\\Phi(x)$, the CDF of the standard normal distribution, and publish them in a book of statistical tables. An example of this is [**this page of normal distribution tables** [PDF]](https://mpaldridge.github.io/math1710/stat-tab.pdf) that will appear on the final page of your exam. (Like the Victorian times, your exam is another place R will not be available but statistical tables will be.)\n\nWe will return to the same questions we answered in the previous subsection, although in a slightly different order.\n\n::: {.thpart}\n**Question 2.**  *Let $Z \\sim \\mathrm{N}(0,1)$. What is $\\mathbb P(Z \\leq 1.45)$?*\n\nAs we noted before, this is asking for $\\Phi(1.45) = \\mathbb P(Z \\leq 1.45)$. Consulting the [statistical tables](https://mpaldridge.github.io/math1710/stat-tab.pdf), we see that the value of $\\Phi(1.45)$ is listed on the table. Specifically, we see from column 3, row 10 of Table 1 that $\\Phi(1.45) = 0.9265$. This is the same value as we got from R (although we get fewer decimal places from the table).\n:::\n\n::: {.thpart}\n**Question 1.**  *A fiberoptic fibre is manufactured with an average width of 8 nanometres (nm), with a standard deviation of 0.04 nm. Fibres that are wider than 8.1 nm fail testing and must be discarded. If the manufactured width is modelled as normally distributed, then what proportion of fibres pass the test?*\n\nIf $X \\sim \\mathrm{N}(8, 0.04^2)$, then this asks for $F_X(8.1) = \\mathbb P(X \\leq 8.1)$. However, unfortunately the statistical tables only have the CDF $\\Phi$ for the standard normal distribution $\\mathrm N(0,1)$. So we are going to have \"standardise\" $X$; that is, convert $X$ to a standard normal distribution.\nRecall from above that we standardise a normal random variable by subtracting the expectation $\\mu$ and dividing by the standard deviation $\\sigma$. So in this case, we have\n\\[ Z = \\frac{X - \\mu}{\\sigma} = \\frac{X - 8}{0.04} \\sim \\mathrm{N}(0,1) . \\]\n\nUsing this, we can write\n\\[ \\mathbb P(X \\leq 8.1) = \\mathbb P \\left(\\frac{X - 8}{0.04} \\leq \\frac{8.1 - 8}{0.04}\\right) = \\mathbb P(Z \\leq 2.5) = \\Phi(2.5).  \\]\nWe can then look up $\\Phi(2.5)$ in Table 1. We see from the first row of the last column that $\\Phi(2.5) = 0.9938$. This matches the answer we got from R.\n:::\n\n::: {.thpart}\n**Question 3.**  *Let $Z \\sim \\mathrm{N}(0,1)$. What is $\\mathbb P(Z > 0.33)$?*\n\nThe statistical tables only have $\\Phi(z) = \\mathbb P(Z \\leq z)$. But as we noted above, $\\mathbb P(Z > 0.33) = 1 - \\Phi(0.33)$. The tables don't have $\\Phi(0.33)$ either, though, because they jump straight from $\\Phi(0.30)$ to $\\Phi(0.35)$. We have two choices of what to do here.\n\nFirst choice, which is appropriate when an approximate answer will suffice, is simply to take the nearest value in the table, which here is $0.35$. Hence\n\\[ \\mathbb P(Z > 0.33) = 1 - \\Phi(0.33) \\approx 1 - \\Phi(0.35) = 1 - 0.6368 = 0.3632 . \\]\nThis is pretty close to the true answer $0.3707$ we saw before: about a 2% error.\n\nSecond choice, which is more work but gets a more accurate answer, is to use interpolation. We know from the table that $\\Phi(0.30) = 0.6179$ and $\\Phi(0.35) = 0.6368$. To \"interpolate\", we assume that the graph of $\\Phi$ follows a straight line between $(0.30, 0.6179)$ and $(0.35, 0.6368)$. (In fact, $\\Phi$ has a slightly curve, so isn't *quite* straight.) As the statistical tables state, the interpolation is to take\n\\[ \\Phi(x) = \\frac{x_2 - x}{x_2 - x_1} \\Phi(x_1) + \\frac{x - x_1}{x_2 - x_1} \\Phi(x_2) .\\]\nIn our case, if we take $x_1 = 0.30$ and $x_2 = 0.35$ as the interpolation points for $x = 0.33$, we get the approximation\n\\[ \\Phi(0.33) = 0.4 \\Phi(0.30) + 0.6 \\Phi(0.35) = 0.4\\times 0.6179 + 0.6 \\times 0.6368 = 0.6292 \\]\nThis is off by only 0.01%; a very accurate approximation.\n:::\n\nOn problem sheets or in the exam, you will be told if an interpolation is necessary.\n\n::: {.thpart}\n**Question 4.** *We return to the fiberoptic model $X \\sim \\mathrm{N}(8, 0.04^2)$ from Question 1. Fibres can be awarded a special \"high quality\" stamp if their width is between 7.95 and 8.05 nm. What proportion of these fibres qualify?*\n\nAs noted above, this is asking for $\\mathbb P(7.95 \\leq X \\leq 8.05)$. To allow us to use our statistical tables, we will have to standardise. We get\n\\begin{align*}\n\\mathbb P(7.95 \\leq X \\leq 8.05)\n  &= \\mathbb P \\left(\\frac{7.95 - 8}{0.04} \\leq \\frac{X - 8}{0.04} \\leq \\frac{8.05 - 8}{0.04}\\right) \\\\\n  &= \\mathbb P(-1.25 \\leq Z \\leq 1.25) \\\\\n  &= \\Phi(1.25) - \\Phi(-1.25) .\n\\end{align*}\nWe can find $\\Phi(1.25) = 0.8944$ from the table. But the table only gives $\\Phi(x)$ for positive $x$, so we can't look up $\\Phi(-1.25)$.\n\nInstead, we can use the symmetry of the normal distribution. Because the standard normal is symmetric about 0, we have that $\\mathbb P(Z \\leq -1.25) = \\mathbb P(Z > 1.25)$.\n\n```{r phiz-exm, echo = FALSE, cache = TRUE}\ncurve(dnorm, from = -4, to = 4, n = 1001, xlim = c(-3, 3), lwd = 2, col = \"blue\", xlab = \"z\", ylab = expression(Phi(z)))\n\nrng <- seq(-3.5, -1.25, by = 0.1)\nxpol <- c(-3.5, rng, -1.25)\nypol <- c(0, dnorm(rng), 0)\npolygon(xpol, ypol, col = \"lightblue1\", border = NA)\n\nrng <- seq(3.5, 1.25, by = -0.1)\nxpol <- c(3.5, rng, 1.25)\nypol <- c(0, dnorm(rng), 0)\npolygon(xpol, ypol, col = \"lightblue1\", border = NA)\n\ncurve(dnorm, from = -4, to = 4, n = 1001, lwd = 3, col = \"blue\", add = TRUE)\n```\nTherefore, we have\n\\[ \\Phi(-1.25) = \\mathbb P(Z > 1.25) = 1 - \\Phi(1.25) = 1 - 0.8944 = 0.1056\\]\n\nPutting this all together, we get\n\\[\\mathbb P(7.95 \\leq X \\leq 8.05) = 0.8944 - 0.1056 = 0.7888 , \\]\nwhich is the same thing as we got from R (up to a small rounding error in the fourth decimal place).\n:::\n\n::: {.thpart}\n**Question 5.** *We stay with the fiberoptic model $X \\sim \\mathrm{N}(8, 0.04^2)$ from Questions 1 and 4. The manufacturer wants to be able to advertise that 99.9% of their fibres are between lower and upper limits $x$ and $y$. What values of $x$ and $y$ can they promise?*\n\nRecall that this meant we were looking for the quantiles $F^{-1}(0.0005)$ and $F^{-1}(0.9995)$; that is, the values $x$ and $y$ such that $\\mathbb P(X \\leq x) = 0.0005$ and $\\mathbb P(X \\leq x) = 0.9995$. Table 2 of the [statistical tables](https://mpaldridge.github.io/math1710/stat-tab.pdf) does show us some quantiles for a standard normal. How can we use these?\n\nLet's start with the second case. The key here is to \"undo\" the standardisation. That is, if $Z \\sim \\mathrm{N}(0,1)$, then $X = \\sigma Z + \\mu \\sim \\mathrm{N}(\\mu, \\sigma^2)$. The table tells us that $\\Phi^{-1}(0.9995) = 3.2905$; that is, that $\\mathbb P(Z \\leq 3.2905) = 0.9995$. Then by \"un-standardising\", we have\n\\[ 0.9995 = \\mathbb P(Z \\leq 3.2905)  = \\mathbb P(0.04Z + 8 \\leq 0.04\\times 3.2905 + 8) = \\mathbb P(X \\leq 8.1316) . \\]\nThis the upper quantile we are after is $8.1316$.\n\nFor the lower quantile, we can use symmetry again. Thus the $0.0005 = 1 - 0.9995$ quantile for $Z$ is minus the previous quantile; that is, $-3.2905$. Hence the lower quantile we want is\n\\[0.04\\times (-3.2905) + 8 = 7.8684. \\]\nThese match the answers we got with R.\n:::\n\nI feel I shouldn't finish with this subsection before addressing the following question some readers may be asking themselves: *Now that we have R (and other computing methods), what's the point learning to answer questions using statistical tables?* I might suggest a few possible answers to this question:\n\n1. Although using statistical tables is an archaic skill, in order to use the statistical tables, you will need to know and be able to apply many facts about probability distributions in general and the normal distribution in particular. So this is a good way to learn those facts and practice their application.\n1. Someone has to write the computer program, and these people need to be able to do the sorts of conversions we will learn about here. So these are useful skills for mathematician--programmers to learn.\n1. Being able to standardise normal distributions, approximate other distributions by normal distributions (see Lecture 18), and so on, are actually important to be able to solve purely mathematical problems, quite outside of merely performing calculations.\n1. Yes, you are right, this is a pointless skill for us to teach you.\n\nI am mostly convinced by answers 1 to 3, although I must admit that answer 4 isn't totally without merit.\n\n## Summary  {#summary-L16 .unnumbered}\n\n::: {.mysummary}\n* The normal distribution has PDF\n\\[ f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp \\left(- \\frac{(x - \\mu)^2}{2\\sigma^2} \\right) .\\]\nIt has expectation $\\mu$ and variance $\\sigma^2$.\n* The standard normal distribution has $\\mu = 0$ and $\\sigma^2 = 1$.\n* The CDF of a normal distribution can be calculated in R with the `pnorm()` function. It can also be calculated using [statistical tables](https://mpaldridge.github.io/math1710/stat-tab.pdf) and by \"standardising\".\n:::"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"L17-normal.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.475","theme":"cosmo","toc-title":"MATH1710"},"extensions":{"book":{"multiFile":true}}},"pdf":{"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"L17-normal.pdf"},"language":{},"metadata":{"block-headings":true,"documentclass":"report"},"extensions":{"book":{}}}}}